{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cf4ac1",
   "metadata": {},
   "source": [
    "## Notebook set up\n",
    "\n",
    "**Your task**: Apply at least two different feature engineering techniques to the `housing_df` dataframe to improve the dataset. At the end of the notebook, your engineered dataset and the original dataset will be used to train a linear regression model to predict `MedHouseVal`. Your goal is to achieve better model performance via feature engineering.\n",
    "\n",
    "**Note**: If you have read ahead or you are familiar with the basics of training ML models, no there is no train-test split and yes, this means data leakage/genralizability is a concern. We will cover those topics in the next unit. For now, the goal is to keep things simple while still giving you an idea of how your feature engineering effects model performance.\n",
    "\n",
    "Before applying transformations, explore the dataset to understand what techniques would be most beneficial.\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be57799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(315)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f01df0",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857336f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "original_housing_df = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "housing_df = original_housing_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3f456",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 1: Explore the dataset\n",
    "\n",
    "Before deciding what feature engineering techniques to apply, explore the dataset to understand its characteristics.\n",
    "\n",
    "**Things to investigate**:\n",
    "- Display basic information about the dataset (`.info()`, `.describe()`)\n",
    "- Check for missing values\n",
    "- Examine feature distributions (histograms, box plots)\n",
    "- Look at feature scales and ranges\n",
    "\n",
    "Use this exploration to inform your feature engineering decisions in the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723510a-a842-401a-934a-5da1f38d8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2214750-9939-4419-b984-f022489731f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28428d0-b1d9-4b84-9fc2-6ddd2c7ee894",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8992807-6e51-4221-95d8-d6e204c4169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return np.log1p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc2eb6-354d-4ec1-818d-5c7d7af03603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_and_log(df, count_cols, bins=50, include_log=False):\n",
    "    \"\"\"\n",
    "    For each column in count_cols, plot:\n",
    "      1) Regular histogram with mean, median, and mode lines (all red)\n",
    "      2) log1p-transformed histogram (handling zeros/negatives with a shift),\n",
    "         also with mean, median, and mode lines (all red) if include_log is True.\n",
    "    Saves both plots as PNGs.\n",
    "    \"\"\"\n",
    "    for c in count_cols:\n",
    "        # Drop NaNs and ensure float\n",
    "        x = np.asarray(df[c].dropna(), dtype=float)\n",
    "        if x.size == 0:\n",
    "            print(f\"Column {c} has no non-NaN values, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Statistics for original data ---\n",
    "        mean_val = np.mean(x)\n",
    "        median_val = np.median(x)\n",
    "        mode_series = pd.Series(x).mode()\n",
    "        mode_val = mode_series.iloc[0] if not mode_series.empty else None\n",
    "\n",
    "        # --- Regular histogram ---\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(x, bins=bins)\n",
    "\n",
    "        # Vertical lines for mean, median, mode (all red)\n",
    "        ax.axvline(mean_val,   color=\"red\", linestyle=\"--\", label=f\"Mean: {mean_val:.2f}\")\n",
    "        ax.axvline(median_val, color=\"red\", linestyle=\"-.\", label=f\"Median: {median_val:.2f}\")\n",
    "        if mode_val is not None:\n",
    "            ax.axvline(mode_val, color=\"red\", linestyle=\":\", label=f\"Mode: {mode_val:.2f}\")\n",
    "\n",
    "        ax.set_title(f\"Histogram: {c}\")\n",
    "        ax.set_xlabel(c)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "        if not include_log:\n",
    "            continue\n",
    "\n",
    "        # --- Log1p histogram (with shift so we can take log) ---\n",
    "        x_log = logit(x)\n",
    "\n",
    "        # Stats in log space\n",
    "        mean_log = np.mean(x_log)\n",
    "        median_log = np.median(x_log)\n",
    "        mode_log_series = pd.Series(x_log).mode()\n",
    "        mode_log = mode_log_series.iloc[0] if not mode_log_series.empty else None\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(x_log, bins=bins)\n",
    "\n",
    "        ax.axvline(mean_log,   color=\"red\", linestyle=\"--\", label=f\"Mean (log): {mean_log:.2f}\")\n",
    "        ax.axvline(median_log, color=\"red\", linestyle=\"-.\", label=f\"Median (log): {median_log:.2f}\")\n",
    "        if mode_log is not None:\n",
    "            ax.axvline(mode_log, color=\"red\", linestyle=\":\", label=f\"Mode (log): {mode_log:.2f}\")\n",
    "\n",
    "        ax.set_title(f\"Histogram (log1p): {c}\")\n",
    "        ax.set_xlabel(f\"log1p({c})\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f98afd-2e23-4c72-a5c6-4ee737bb588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_lat = 36.8\n",
    "coast_lon = -122.0\n",
    "housing_df[\"DistToCoast2\"] = np.sqrt(\n",
    "    (housing_df[\"Latitude\"] - coast_lat)**2 +\n",
    "    (housing_df[\"Longitude\"] - coast_lon)**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c72dc-fba3-47c1-9ebf-c2e81f6dba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"LatLon\"] = housing_df[\"Latitude\"] * housing_df[\"Longitude\"]\n",
    "housing_df[\"LatDivLon\"] = housing_df[\"Latitude\"] / housing_df[\"Longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd414ff-d743-43f3-964a-059be9fbe1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "housing_df[\"PopDensity\"] = housing_df[\"Population\"] / (\n",
    "    (housing_df[\"Latitude\"] - housing_df[\"Latitude\"].mean())**2 +\n",
    "    (housing_df[\"Longitude\"] - housing_df[\"Longitude\"].mean())**2 + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337cb2b-2082-4493-847f-1b5713328a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\",\n",
    "    \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\",\n",
    "    \"MedHouseVal\", \"BedroomsPerOccupant\", \"RoomsPerOccupant\",\n",
    "    \"BedrmsPerRoom\", \"RoomsPerPerson\", \"PopPerHousehold\", \"DistToCoast\", \n",
    "    \"DistToCoast2\", \"LatLon\",\"LatDivLon\", \"PopDensity\"\n",
    "]\n",
    "\n",
    "num_cols = housing_df.select_dtypes(include=[\"number\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af1ed8-ec36-4b97-b955-6e29bd08afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_and_log(housing_df, num_cols,include_log =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8d6eb-226c-4448-b20a-7304282e991d",
   "metadata": {},
   "outputs": [],
   "source": [
    " n_bins = 10\n",
    "\n",
    "# Equal-width bins for Latitude\n",
    "lat_edges = np.linspace(housing_df[\"Latitude\"].min(),\n",
    "                        housing_df[\"Latitude\"].max(),\n",
    "                        n_bins + 1)\n",
    "\n",
    "housing_df[\"Lat_bin_idx\"] = pd.cut(\n",
    "    housing_df[\"Latitude\"],\n",
    "    bins=lat_edges,\n",
    "    labels=False,          # <- gives 0,1,2,... instead of (37.81, 38.48]\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Normalize to [0,1]\n",
    "housing_df[\"Lat_bin_norm\"] = housing_df[\"Lat_bin_idx\"] / (n_bins - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d9b71-eb23-4ce7-a366-2dc8ceaf94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c3893-993c-4b22-9ac6-4d7ee8e92271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(data=housing_df, x=col, bins=30, kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5285883-559f-4a33-bbdc-f73ee3f064f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[numeric_cols].hist(bins=30, figsize=(12, 10), layout=(3, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f95c7-7f4d-4bc2-9489-428ba1e43ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing_df.corr(numeric_only=True)\n",
    "\n",
    "# 2. Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,        # show the correlation numbers\n",
    "    fmt=\".2f\",         # format to 2 decimal places\n",
    "    cmap=\"coolwarm\",   # red/blue style colormap\n",
    "    center=0           # 0 correlation at the middle color\n",
    ")\n",
    "plt.title(\"Correlation Heatmap of Housing Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4399a5",
   "metadata": {},
   "source": [
    "## Task 2: Apply your first feature engineering technique\n",
    "\n",
    "Based on your exploration, apply your first feature engineering technique.\n",
    "\n",
    "**Example approaches**:\n",
    "- Transform skewed features using log, sqrt, power, or quantile transformations\n",
    "- Create bins/categories from continuous variables\n",
    "- Create interaction features (e.g., rooms per household = total rooms / households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9a5f9-d86a-41f6-9f9b-2a4302fe79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = [\"MedInc\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\"]\n",
    "for col in skewed_cols:\n",
    "    housing_df[col] = logit(housing_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2702fc-eced-4fb3-9f19-95e58a72d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"RoomsPerBedroom\"] = housing_df[\"AveRooms\"] / housing_df[\"AveBedrms\"]\n",
    "housing_df[\"BedroomsPerOccupant\"] = housing_df[\"AveBedrms\"] / housing_df[\"AveOccup\"]\n",
    "housing_df[\"RoomsPerOccupant\"] = housing_df[\"AveRooms\"] / housing_df[\"AveOccup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bb285-f884-4b88-9fc3-de7e934d8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"BedrmsPerRoom\"] = housing_df[\"AveBedrms\"] / housing_df[\"AveRooms\"]\n",
    "housing_df[\"RoomsPerPerson\"] = housing_df[\"AveRooms\"] / housing_df[\"AveOccup\"]\n",
    "housing_df[\"PopPerHousehold\"] = housing_df[\"Population\"] / housing_df[\"AveOccup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57d4c6-c123-4d6d-9250-e440a1d25e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_mean = housing_df[\"Latitude\"].mean()\n",
    "lon_mean = housing_df[\"Longitude\"].mean()\n",
    "\n",
    "# Distance to the \"center\" of the data (in degrees, not true km, but good enough as a feature)\n",
    "housing_df[\"DistFromMean\"] = np.sqrt(\n",
    "    (housing_df[\"Latitude\"] - lat_mean)**2 +\n",
    "    (housing_df[\"Longitude\"] - lon_mean)**2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c419f-0437-4ff5-b93b-5b3aba559e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c03c59-1e24-42df-a74a-7025d5f10280",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_cols =  [\"LatRegion_Lat_Q1\", \"LatRegion_Lat_Q2\", \"LatRegion_Lat_Q3\", \"LatRegion_Lat_Q4\"]\n",
    "cost_col =  [\"DistToCoast\", \"DistToCoast2\"]\n",
    "lat_bin_col =  [\"Lat_bin_norm\", \"Lat_bin_idx\"]\n",
    "housing_df = housing_df.drop(lat_bin_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03fedc-2971-4c03-b2a0-0591ee7ea687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple interaction term\n",
    "housing_df[\"LatRegion\"] = pd.qcut(\n",
    "    housing_df[\"Latitude\"],\n",
    "    q=4,\n",
    "    labels=[\"Lat_Q1\", \"Lat_Q2\", \"Lat_Q3\", \"Lat_Q4\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689af61-a71f-4e2e-9441-067740ee9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"DistToCoast\"] = abs(housing_df[\"Longitude\"] + 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e8b05-cf7b-4fba-9922-909fa48b83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"DistToCoast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a53e9-6d21-471b-a45e-24c9d3b5ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_df[\"Lat_Lon_Interaction\"] = housing_df[\"Latitude\"] * housing_df[\"Longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398dc539-ac8b-4650-9bcd-4bdfe0cc09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Choose how many regions you want (try 5, 8, 10, etc.)\n",
    "N_CLUSTERS = 8\n",
    "\n",
    "coords = housing_df[[\"Latitude\", \"Longitude\"]]\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    random_state=42,\n",
    "    n_init=\"auto\"   # or an int like 10 if you get a warning\n",
    ")\n",
    "\n",
    "housing_df[\"LocationCluster\"] = kmeans.fit_predict(coords)\n",
    "\n",
    "housing_df[\"LocationCluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110a0a2",
   "metadata": {},
   "source": [
    "## Task 3: Apply your second feature engineering technique\n",
    "\n",
    "**Example approaches**:\n",
    "- Scale features to similar ranges\n",
    "- Encode any categorical variables you created\n",
    "- Create aggregate statistics by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c2905-1f9b-48a7-9a9f-cb8f6fec51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "onehot_array = encoder.fit_transform(housing_df[['LatRegion']])\n",
    "\n",
    "# Create dataframe with proper column names\n",
    "df_onehot = pd.DataFrame(\n",
    "    onehot_array,\n",
    "    columns=encoder.get_feature_names_out(['LatRegion']),\n",
    "    index=housing_df.index\n",
    ")\n",
    "\n",
    "df_onehot\n",
    "\n",
    "housing_df = pd.concat([housing_df.drop(\"LatRegion\", axis=1), df_onehot], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6aec21-5fa9-4d1a-ab46-5263363d63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c775d3-c276-4092-8f02-84015e49142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Look at the one-hot dataframe\n",
    "display(df_onehot.head())\n",
    "\n",
    "# 2. Get counts for each region (summing 0/1 columns)\n",
    "region_counts = df_onehot.sum(axis=0)\n",
    "\n",
    "# 3. Plot as a bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    x=region_counts.index,\n",
    "    y=region_counts.values\n",
    ")\n",
    "\n",
    "plt.title(\"Frequency of Latitude Regions (One-Hot Encoded)\")\n",
    "plt.xlabel(\"LatRegion (one-hot columns)\")\n",
    "plt.ylabel(\"Number of rows\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90f141",
   "metadata": {},
   "source": [
    "## (Optional) Additional feature engineering\n",
    "\n",
    "Add more techniques if you'd like to experiment further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "housing_df[\"HouseAge_pt\"] = pt.fit_transform(housing_df[[\"HouseAge\"]])\n",
    "housing_df[\"AveRooms_pt\"] = pt.fit_transform(housing_df[[\"AveRooms\"]])\n",
    "housing_df[\"AveOccup_pt\"] = pt.fit_transform(housing_df[[\"AveOccup\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7be947-0e1f-4a82-8b20-4dd29e3d3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "qt = QuantileTransformer(output_distribution=\"uniform\")\n",
    "housing_df[\"Lat_uniform\"] = qt.fit_transform(housing_df[[\"Latitude\"]])\n",
    "housing_df[\"Lon_uniform\"] = qt.fit_transform(housing_df[[\"Longitude\"]])\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "housing_df[\"Lat_z\"] = sc.fit_transform(housing_df[[\"Latitude\"]])\n",
    "housing_df[\"Lon_z\"] = sc.fit_transform(housing_df[[\"Longitude\"]])\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11834ffc",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Now we'll compare model performance on the original dataset versus your engineered dataset.\n",
    "\n",
    "### Evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_directory = 'data/outputs'\n",
    "Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save a copy of the engineered dataframe\n",
    "housing_df.to_csv('data/outputs/housing_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Evaluate on original dataset\n",
    "scores_original = cross_val_score(\n",
    "    model,\n",
    "    original_housing_df.drop('MedHouseVal', axis=1),\n",
    "    original_housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Evaluate on engineered dataset\n",
    "scores_engineered = cross_val_score(\n",
    "    model,\n",
    "    housing_df.drop('MedHouseVal', axis=1),\n",
    "    housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "engineered_mean = scores_engineered.mean()\n",
    "original_mean = scores_original.mean()\n",
    "mean_improvement = (engineered_mean - original_mean) / original_mean\n",
    "\n",
    "print(f'\\nMean improvement: {mean_improvement:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017b15b",
   "metadata": {},
   "source": [
    "### Visualize model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = LinearRegression()\n",
    "original_model.fit(original_housing_df.drop('MedHouseVal', axis=1), original_housing_df['MedHouseVal'])\n",
    "original_predictions = original_model.predict(original_housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(housing_df.drop('MedHouseVal', axis=1), housing_df['MedHouseVal'])\n",
    "predictions = model.predict(housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "# Create boxplot comparing performance\n",
    "data_to_plot = [scores_original, scores_engineered]\n",
    "labels = ['Original', 'Engineered']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4.5))\n",
    "\n",
    "fig.suptitle(f'Model performance comparison\\nmean improvement: {mean_improvement:.2f}%')\n",
    "\n",
    "axs[0].set_title('Cross validation R² scores')\n",
    "axs[0].boxplot(data_to_plot, labels=labels)\n",
    "axs[0].set_xlabel('Dataset')\n",
    "axs[0].set_ylabel('R² score')\n",
    "\n",
    "axs[1].set_title('Predictions vs true values')\n",
    "axs[1].plot(\n",
    "    original_housing_df['MedHouseVal'], original_predictions,\n",
    "    'o', markersize=1, label='Original', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].plot(\n",
    "    housing_df['MedHouseVal'], predictions,\n",
    "    'o', markersize=1, label='Engineered', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].set_xlabel('True Values')\n",
    "axs[1].set_ylabel('Predictions')\n",
    "\n",
    "leg = axs[1].legend(loc='upper left', markerscale=8, framealpha=1)\n",
    "\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bc24e",
   "metadata": {},
   "source": [
    "## 3. Reflection\n",
    "\n",
    "**Questions to consider**:\n",
    "\n",
    "1. Which feature engineering techniques had the biggest impact on model performance?\n",
    "2. Did adding more features always improve performance, or did some hurt it?\n",
    "3. How might you further improve the engineered dataset?\n",
    "4. What trade-offs did you consider (e.g., interpretability vs performance, complexity vs gains)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f57096",
   "metadata": {},
   "source": [
    "**Your reflection**:\n",
    "\n",
    "*Write your thoughts here...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

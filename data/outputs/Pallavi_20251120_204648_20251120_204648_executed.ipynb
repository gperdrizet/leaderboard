{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f68622e",
   "metadata": {
    "papermill": {
     "duration": 0.004116,
     "end_time": "2025-11-20T19:46:50.403360",
     "exception": false,
     "start_time": "2025-11-20T19:46:50.399244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook set up\n",
    "\n",
    "Submit your notebook to the class leaderboard on HuggingFace at [huggingface.co/spaces/gperdrizet/leaderboard](https://huggingface.co/spaces/gperdrizet/leaderboard)\n",
    "\n",
    "**Your task**: Apply at least two different feature engineering techniques to the `housing_df` dataframe to improve the dataset. At the end of the notebook, your engineered dataset and the original dataset will be used to train a linear regression model to predict `MedHouseVal`. Your goal is to achieve better model performance via feature engineering.\n",
    "\n",
    "Don't change any of the code in the Model evaluation section of the notebook, especially the output saving. Otherwise the leaderboard scoring may not work!\n",
    "\n",
    "**Note**: If you have read ahead or you are familiar with the basics of training ML models, no there is no train-test split and yes, this means data leakage/genralizability is a concern. We will cover those topics in the next unit. For now, the goal is to keep things simple while still giving you an idea of how your feature engineering effects model performance.\n",
    "\n",
    "Before applying transformations, explore the dataset to understand what techniques would be most beneficial.\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb47379c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:46:50.412167Z",
     "iopub.status.busy": "2025-11-20T19:46:50.411920Z",
     "iopub.status.idle": "2025-11-20T19:46:51.988227Z",
     "shell.execute_reply": "2025-11-20T19:46:51.987385Z"
    },
    "papermill": {
     "duration": 1.581849,
     "end_time": "2025-11-20T19:46:51.988949",
     "exception": false,
     "start_time": "2025-11-20T19:46:50.407100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/site-packages (from seaborn) (2.2.6)\r\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/site-packages (from seaborn) (2.3.3)\r\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/site-packages (from seaborn) (3.10.7)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47ed928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:46:51.998655Z",
     "iopub.status.busy": "2025-11-20T19:46:51.998418Z",
     "iopub.status.idle": "2025-11-20T19:46:54.363985Z",
     "shell.execute_reply": "2025-11-20T19:46:54.363177Z"
    },
    "papermill": {
     "duration": 2.371881,
     "end_time": "2025-11-20T19:46:54.364879",
     "exception": false,
     "start_time": "2025-11-20T19:46:51.992998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import (\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    StandardScaler\n",
    "   \n",
    ")\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(315)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860dc5b9",
   "metadata": {
    "papermill": {
     "duration": 0.003684,
     "end_time": "2025-11-20T19:46:54.372478",
     "exception": false,
     "start_time": "2025-11-20T19:46:54.368794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3cbb68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:46:54.381365Z",
     "iopub.status.busy": "2025-11-20T19:46:54.381003Z",
     "iopub.status.idle": "2025-11-20T19:46:54.495687Z",
     "shell.execute_reply": "2025-11-20T19:46:54.494827Z"
    },
    "papermill": {
     "duration": 0.120259,
     "end_time": "2025-11-20T19:46:54.496561",
     "exception": false,
     "start_time": "2025-11-20T19:46:54.376302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "original_housing_df = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "housing_df = original_housing_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95947767",
   "metadata": {
    "papermill": {
     "duration": 0.003848,
     "end_time": "2025-11-20T19:46:54.504294",
     "exception": false,
     "start_time": "2025-11-20T19:46:54.500446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 1: Explore the dataset\n",
    "\n",
    "Before deciding what feature engineering techniques to apply, explore the dataset to understand its characteristics.\n",
    "\n",
    "**Things to investigate**:\n",
    "- Display basic information about the dataset (`.info()`, `.describe()`)\n",
    "- Check for missing values\n",
    "- Examine feature distributions (histograms, box plots)\n",
    "- Look at feature scales and ranges\n",
    "\n",
    "Use this exploration to inform your feature engineering decisions in the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9efd8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:46:54.513332Z",
     "iopub.status.busy": "2025-11-20T19:46:54.513032Z",
     "iopub.status.idle": "2025-11-20T19:47:09.346486Z",
     "shell.execute_reply": "2025-11-20T19:47:09.345678Z"
    },
    "papermill": {
     "duration": 14.839158,
     "end_time": "2025-11-20T19:47:09.347170",
     "exception": false,
     "start_time": "2025-11-20T19:46:54.508012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n",
      "None\n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude   MedHouseVal  \n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704      2.068558  \n",
      "std       10.386050      2.135952      2.003532      1.153956  \n",
      "min        0.692308     32.540000   -124.350000      0.149990  \n",
      "25%        2.429741     33.930000   -121.800000      1.196000  \n",
      "50%        2.818116     34.260000   -118.490000      1.797000  \n",
      "75%        3.282261     37.710000   -118.010000      2.647250  \n",
      "max     1243.333333     41.950000   -114.310000      5.000010  \n",
      "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0       False     False     False      False       False     False     False   \n",
      "1       False     False     False      False       False     False     False   \n",
      "2       False     False     False      False       False     False     False   \n",
      "3       False     False     False      False       False     False     False   \n",
      "4       False     False     False      False       False     False     False   \n",
      "...       ...       ...       ...        ...         ...       ...       ...   \n",
      "20635   False     False     False      False       False     False     False   \n",
      "20636   False     False     False      False       False     False     False   \n",
      "20637   False     False     False      False       False     False     False   \n",
      "20638   False     False     False      False       False     False     False   \n",
      "20639   False     False     False      False       False     False     False   \n",
      "\n",
      "       Longitude  MedHouseVal  \n",
      "0          False        False  \n",
      "1          False        False  \n",
      "2          False        False  \n",
      "3          False        False  \n",
      "4          False        False  \n",
      "...          ...          ...  \n",
      "20635      False        False  \n",
      "20636      False        False  \n",
      "20637      False        False  \n",
      "20638      False        False  \n",
      "20639      False        False  \n",
      "\n",
      "[20640 rows x 9 columns]\n",
      "MedInc         0\n",
      "HouseAge       0\n",
      "AveRooms       0\n",
      "AveBedrms      0\n",
      "Population     0\n",
      "AveOccup       0\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "MedHouseVal    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Display basic information about the dataset (`.info()`, `.describe()`)\n",
    "print(housing_df.info())\n",
    "print(housing_df.describe())\n",
    "#Check for missing values\n",
    "print(housing_df.isnull())\n",
    "print(housing_df.isnull().sum()) # Dont have any missing values\n",
    "#Examine feature distributions (histograms, box plots)\n",
    "\n",
    "# Draw Histograms \n",
    "fig, axes = plt.subplots(4, 2, figsize=(15,20)) # 2 rows, 2 columns\n",
    "\n",
    "\n",
    "# MedInc - Distribution\n",
    "sns.histplot(housing_df['MedInc'], kde=True, color='gray', label='Original', ax=axes[0,0],alpha=0.5)\n",
    "axes[0,0].set_title('MedInc - Distribution')\n",
    "axes[0,0].set_xlabel('MedInc')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].legend()\n",
    "# HouseAge - Distribution\n",
    "sns.histplot(housing_df['HouseAge'], kde=True, color='green', label='Original', ax=axes[0,1],alpha=0.5)\n",
    "axes[0,1].set_title('HouseAge - Distribution')\n",
    "axes[0,1].set_xlabel('HouseAge')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].legend()\n",
    "# AveRooms  - Distribution\n",
    "sns.histplot(housing_df['AveRooms'], kde=True,color='pink', label='Original', ax=axes[1,0],alpha=0.5)\n",
    "axes[1,0].set_title('AveRooms - Distribution')\n",
    "axes[1,0].set_xlabel('AveRooms')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].legend()\n",
    "# AveBedrms - Distribution\n",
    "sns.histplot(housing_df['AveBedrms'], kde=True, color='blue', label='Original', ax=axes[1,1],alpha=0.5)\n",
    "axes[1,1].set_title('AveBedrms - Distribution')\n",
    "axes[1,1].set_xlabel('AveBedrms ')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].legend()\n",
    "# Population - Distribution\n",
    "sns.histplot(housing_df['Population'], kde=True, color='red', label='Original', ax=axes[2,0],alpha=0.5)\n",
    "axes[2,0].set_title('Population - Distribution')\n",
    "axes[2,0].set_xlabel('Population')\n",
    "axes[2,0].set_ylabel('Frequency')\n",
    "axes[2,0].legend()\n",
    "\n",
    "# AveOccup - Distribution\n",
    "sns.histplot(housing_df['AveOccup'], kde=True, color='red', label='Original', ax=axes[2,1],alpha=0.5)\n",
    "axes[2,1].set_title('AveOccup - Distribution')\n",
    "axes[2,1].set_xlabel('AveOccup')\n",
    "axes[2,1].set_ylabel('Frequency')\n",
    "axes[2,1].legend()\n",
    "\n",
    "# MedHouseVal - Distribution\n",
    "sns.histplot(housing_df['MedHouseVal'], kde=True, color='lightBlue', label='Original', ax=axes[3,0],alpha=0.5)\n",
    "axes[3,0].set_title('MedHouseVal - Distribution')\n",
    "axes[3,0].set_xlabel('MedHouseVal')\n",
    "axes[3,0].set_ylabel('Frequency')\n",
    "axes[3,0].legend()\n",
    "\n",
    "# Longitude adn Latitude - Distribution\n",
    "sns.scatterplot(x=housing_df['Longitude'],y=housing_df['Latitude'], label='Original', ax=axes[3,1],alpha=0.7)\n",
    "axes[3,1].set_title('Longitude - Latitude - Distribution')\n",
    "axes[3,1].set_xlabel('Longitude')\n",
    "axes[3,1].set_ylabel('Latitude')\n",
    "axes[3,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576add86",
   "metadata": {
    "papermill": {
     "duration": 0.004059,
     "end_time": "2025-11-20T19:47:09.355359",
     "exception": false,
     "start_time": "2025-11-20T19:47:09.351300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 2: Apply your first feature engineering technique\n",
    "\n",
    "Based on your exploration, apply your first feature engineering technique.\n",
    "\n",
    "**Example approaches**:\n",
    "- Transform skewed features using log, sqrt, power, or quantile transformations\n",
    "- Create bins/categories from continuous variables\n",
    "- Create interaction features (e.g., rooms per household = total rooms / households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e573d50f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:09.364224Z",
     "iopub.status.busy": "2025-11-20T19:47:09.363976Z",
     "iopub.status.idle": "2025-11-20T19:47:09.728413Z",
     "shell.execute_reply": "2025-11-20T19:47:09.727553Z"
    },
    "papermill": {
     "duration": 0.370175,
     "end_time": "2025-11-20T19:47:09.729259",
     "exception": false,
     "start_time": "2025-11-20T19:47:09.359084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Applying log,sqrt,power or quantile on heavily skewed features AveOccup, AveBedrms and AveRooms\n",
    "\n",
    "# Transform AveOccup\n",
    "feature = 'AveOccup'\n",
    "\n",
    "# Apply log transformation (using log1p to handle zeros)\n",
    "housing_df[f'{feature}_log'] = np.log1p(housing_df[feature])\n",
    "# Apply square root transformation\n",
    "housing_df[f'{feature}_sqrt'] = np.sqrt(housing_df[feature])\n",
    "# Apply power transformation using Yeo-Johnson (handles positive and negative values)\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "# Fit and transform\n",
    "housing_df[f'{feature}_power'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to uniform distribution\n",
    "transformer = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "housing_df[f'{feature}_quantile_uniform'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "housing_df[f'{feature}_quantile_normal'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "\n",
    "axes[0].set_title('Original distribution')\n",
    "axes[0].hist(housing_df[feature], bins=50, edgecolor='black', color='grey')\n",
    "axes[0].set_xlabel(feature)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].set_title('Log-transformed distribution')\n",
    "axes[1].hist(housing_df[f'{feature}_log'], bins=50, edgecolor='black', color='grey')\n",
    "axes[1].set_xlabel(f'{feature}_log')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].set_title('Square root-transformed distribution')\n",
    "axes[2].hist(housing_df[f'{feature}_sqrt'], bins=50, edgecolor='black', color='grey')\n",
    "axes[2].set_xlabel(f'{feature}_sqrt')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "axes[3].set_title('Power-transformed distribution')\n",
    "axes[3].hist(housing_df[f'{feature}_power'], bins=50, edgecolor='black', color='grey')\n",
    "axes[3].set_xlabel(f'{feature}_power')\n",
    "axes[3].set_ylabel('Frequency')\n",
    "\n",
    "axes[4].set_title('Quantile transform (uniform)')\n",
    "axes[4].hist(housing_df[f'{feature}_quantile_uniform'], bins=50, edgecolor='black', color='grey')\n",
    "axes[4].set_xlabel('Uniform [0, 1]')\n",
    "axes[4].set_ylabel('Frequency')\n",
    "\n",
    "axes[5].set_xlabel('Normal distribution')\n",
    "axes[5].set_title('Quantile transform (normal)')\n",
    "axes[5].hist(housing_df[f'{feature}_quantile_normal'], bins=50, edgecolor='black', color='grey')\n",
    "axes[5].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f92207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:09.740002Z",
     "iopub.status.busy": "2025-11-20T19:47:09.739776Z",
     "iopub.status.idle": "2025-11-20T19:47:10.109101Z",
     "shell.execute_reply": "2025-11-20T19:47:10.108215Z"
    },
    "papermill": {
     "duration": 0.376071,
     "end_time": "2025-11-20T19:47:10.109836",
     "exception": false,
     "start_time": "2025-11-20T19:47:09.733765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform AveBedrms\n",
    "feature = 'AveBedrms'\n",
    "\n",
    "# Apply log transformation (using log1p to handle zeros)\n",
    "housing_df[f'{feature}_log'] = np.log1p(housing_df[feature])\n",
    "# Apply square root transformation\n",
    "housing_df[f'{feature}_sqrt'] = np.sqrt(housing_df[feature])\n",
    "# Apply power transformation using Yeo-Johnson (handles positive and negative values)\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "# Fit and transform\n",
    "housing_df[f'{feature}_power'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to uniform distribution\n",
    "transformer = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "housing_df[f'{feature}_quantile_uniform'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "housing_df[f'{feature}_quantile_normal'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "\n",
    "axes[0].set_title('Original distribution')\n",
    "axes[0].hist(housing_df[feature], bins=50, edgecolor='black', color='grey')\n",
    "axes[0].set_xlabel(feature)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].set_title('Log-transformed distribution')\n",
    "axes[1].hist(housing_df[f'{feature}_log'], bins=50, edgecolor='black', color='grey')\n",
    "axes[1].set_xlabel(f'{feature}_log')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].set_title('Square root-transformed distribution')\n",
    "axes[2].hist(housing_df[f'{feature}_sqrt'], bins=50, edgecolor='black', color='grey')\n",
    "axes[2].set_xlabel(f'{feature}_sqrt')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "axes[3].set_title('Power-transformed distribution')\n",
    "axes[3].hist(housing_df[f'{feature}_power'], bins=50, edgecolor='black', color='grey')\n",
    "axes[3].set_xlabel(f'{feature}_power')\n",
    "axes[3].set_ylabel('Frequency')\n",
    "\n",
    "axes[4].set_title('Quantile transform (uniform)')\n",
    "axes[4].hist(housing_df[f'{feature}_quantile_uniform'], bins=50, edgecolor='black', color='grey')\n",
    "axes[4].set_xlabel('Uniform [0, 1]')\n",
    "axes[4].set_ylabel('Frequency')\n",
    "\n",
    "axes[5].set_xlabel('Normal distribution')\n",
    "axes[5].set_title('Quantile transform (normal)')\n",
    "axes[5].hist(housing_df[f'{feature}_quantile_normal'], bins=50, edgecolor='black', color='grey')\n",
    "axes[5].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5877ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:10.119497Z",
     "iopub.status.busy": "2025-11-20T19:47:10.119267Z",
     "iopub.status.idle": "2025-11-20T19:47:10.504259Z",
     "shell.execute_reply": "2025-11-20T19:47:10.503386Z"
    },
    "papermill": {
     "duration": 0.390903,
     "end_time": "2025-11-20T19:47:10.505064",
     "exception": false,
     "start_time": "2025-11-20T19:47:10.114161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform AveRooms\n",
    "feature = 'AveRooms'\n",
    "\n",
    "# Apply log transformation (using log1p to handle zeros)\n",
    "housing_df[f'{feature}_log'] = np.log1p(housing_df[feature])\n",
    "# Apply square root transformation\n",
    "housing_df[f'{feature}_sqrt'] = np.sqrt(housing_df[feature])\n",
    "# Apply power transformation using Yeo-Johnson (handles positive and negative values)\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "# Fit and transform\n",
    "housing_df[f'{feature}_power'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to uniform distribution\n",
    "transformer = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "housing_df[f'{feature}_quantile_uniform'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "housing_df[f'{feature}_quantile_normal'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "\n",
    "axes[0].set_title('Original distribution')\n",
    "axes[0].hist(housing_df[feature], bins=50, edgecolor='black', color='grey')\n",
    "axes[0].set_xlabel(feature)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].set_title('Log-transformed distribution')\n",
    "axes[1].hist(housing_df[f'{feature}_log'], bins=50, edgecolor='black', color='grey')\n",
    "axes[1].set_xlabel(f'{feature}_log')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].set_title('Square root-transformed distribution')\n",
    "axes[2].hist(housing_df[f'{feature}_sqrt'], bins=50, edgecolor='black', color='grey')\n",
    "axes[2].set_xlabel(f'{feature}_sqrt')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "axes[3].set_title('Power-transformed distribution')\n",
    "axes[3].hist(housing_df[f'{feature}_power'], bins=50, edgecolor='black', color='grey')\n",
    "axes[3].set_xlabel(f'{feature}_power')\n",
    "axes[3].set_ylabel('Frequency')\n",
    "\n",
    "axes[4].set_title('Quantile transform (uniform)')\n",
    "axes[4].hist(housing_df[f'{feature}_quantile_uniform'], bins=50, edgecolor='black', color='grey')\n",
    "axes[4].set_xlabel('Uniform [0, 1]')\n",
    "axes[4].set_ylabel('Frequency')\n",
    "\n",
    "axes[5].set_xlabel('Normal distribution')\n",
    "axes[5].set_title('Quantile transform (normal)')\n",
    "axes[5].hist(housing_df[f'{feature}_quantile_normal'], bins=50, edgecolor='black', color='grey')\n",
    "axes[5].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97f5cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:10.515018Z",
     "iopub.status.busy": "2025-11-20T19:47:10.514773Z",
     "iopub.status.idle": "2025-11-20T19:47:11.887839Z",
     "shell.execute_reply": "2025-11-20T19:47:11.886920Z"
    },
    "papermill": {
     "duration": 1.379205,
     "end_time": "2025-11-20T19:47:11.888543",
     "exception": false,
     "start_time": "2025-11-20T19:47:10.509338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform MedInc\n",
    "feature = 'MedInc'\n",
    "\n",
    "# Apply log transformation (using log1p to handle zeros)\n",
    "housing_df[f'{feature}_log'] = np.log1p(housing_df[feature])\n",
    "# Apply square root transformation\n",
    "housing_df[f'{feature}_sqrt'] = np.sqrt(housing_df[feature])\n",
    "# Apply power transformation using Yeo-Johnson (handles positive and negative values)\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "# Fit and transform\n",
    "housing_df[f'{feature}_power'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to uniform distribution\n",
    "transformer = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "housing_df[f'{feature}_quantile_uniform'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "housing_df[f'{feature}_quantile_normal'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "\n",
    "axes[0].set_title('Original distribution')\n",
    "axes[0].hist(housing_df[feature], bins=50, edgecolor='black', color='grey')\n",
    "axes[0].set_xlabel(feature)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].set_title('Log-transformed distribution')\n",
    "axes[1].hist(housing_df[f'{feature}_log'], bins=50, edgecolor='black', color='grey')\n",
    "axes[1].set_xlabel(f'{feature}_log')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].set_title('Square root-transformed distribution')\n",
    "axes[2].hist(housing_df[f'{feature}_sqrt'], bins=50, edgecolor='black', color='grey')\n",
    "axes[2].set_xlabel(f'{feature}_sqrt')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "axes[3].set_title('Power-transformed distribution')\n",
    "axes[3].hist(housing_df[f'{feature}_power'], bins=50, edgecolor='black', color='grey')\n",
    "axes[3].set_xlabel(f'{feature}_power')\n",
    "axes[3].set_ylabel('Frequency')\n",
    "\n",
    "axes[4].set_title('Quantile transform (uniform)')\n",
    "axes[4].hist(housing_df[f'{feature}_quantile_uniform'], bins=50, edgecolor='black', color='grey')\n",
    "axes[4].set_xlabel('Uniform [0, 1]')\n",
    "axes[4].set_ylabel('Frequency')\n",
    "\n",
    "axes[5].set_xlabel('Normal distribution')\n",
    "axes[5].set_title('Quantile transform (normal)')\n",
    "axes[5].hist(housing_df[f'{feature}_quantile_normal'], bins=50, edgecolor='black', color='grey')\n",
    "axes[5].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1601d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:11.898528Z",
     "iopub.status.busy": "2025-11-20T19:47:11.898292Z",
     "iopub.status.idle": "2025-11-20T19:47:12.258452Z",
     "shell.execute_reply": "2025-11-20T19:47:12.257679Z"
    },
    "papermill": {
     "duration": 0.366436,
     "end_time": "2025-11-20T19:47:12.259333",
     "exception": false,
     "start_time": "2025-11-20T19:47:11.892897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform Population\n",
    "feature = 'Population'\n",
    "\n",
    "# Apply log transformation (using log1p to handle zeros)\n",
    "housing_df[f'{feature}_log'] = np.log1p(housing_df[feature])\n",
    "# Apply square root transformation\n",
    "housing_df[f'{feature}_sqrt'] = np.sqrt(housing_df[feature])\n",
    "# Apply power transformation using Yeo-Johnson (handles positive and negative values)\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "# Fit and transform\n",
    "housing_df[f'{feature}_power'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to uniform distribution\n",
    "transformer = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "housing_df[f'{feature}_quantile_uniform'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "housing_df[f'{feature}_quantile_normal'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "\n",
    "axes[0].set_title('Original distribution')\n",
    "axes[0].hist(housing_df[feature], bins=50, edgecolor='black', color='grey')\n",
    "axes[0].set_xlabel(feature)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].set_title('Log-transformed distribution')\n",
    "axes[1].hist(housing_df[f'{feature}_log'], bins=50, edgecolor='black', color='grey')\n",
    "axes[1].set_xlabel(f'{feature}_log')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].set_title('Square root-transformed distribution')\n",
    "axes[2].hist(housing_df[f'{feature}_sqrt'], bins=50, edgecolor='black', color='grey')\n",
    "axes[2].set_xlabel(f'{feature}_sqrt')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "axes[3].set_title('Power-transformed distribution')\n",
    "axes[3].hist(housing_df[f'{feature}_power'], bins=50, edgecolor='black', color='grey')\n",
    "axes[3].set_xlabel(f'{feature}_power')\n",
    "axes[3].set_ylabel('Frequency')\n",
    "\n",
    "axes[4].set_title('Quantile transform (uniform)')\n",
    "axes[4].hist(housing_df[f'{feature}_quantile_uniform'], bins=50, edgecolor='black', color='grey')\n",
    "axes[4].set_xlabel('Uniform [0, 1]')\n",
    "axes[4].set_ylabel('Frequency')\n",
    "\n",
    "axes[5].set_xlabel('Normal distribution')\n",
    "axes[5].set_title('Quantile transform (normal)')\n",
    "axes[5].hist(housing_df[f'{feature}_quantile_normal'], bins=50, edgecolor='black', color='grey')\n",
    "axes[5].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff70151e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:12.268986Z",
     "iopub.status.busy": "2025-11-20T19:47:12.268754Z",
     "iopub.status.idle": "2025-11-20T19:47:12.640641Z",
     "shell.execute_reply": "2025-11-20T19:47:12.639888Z"
    },
    "papermill": {
     "duration": 0.37753,
     "end_time": "2025-11-20T19:47:12.641133",
     "exception": false,
     "start_time": "2025-11-20T19:47:12.263603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 39 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   MedInc                        20640 non-null  float64\n",
      " 1   HouseAge                      20640 non-null  float64\n",
      " 2   AveRooms                      20640 non-null  float64\n",
      " 3   AveBedrms                     20640 non-null  float64\n",
      " 4   Population                    20640 non-null  float64\n",
      " 5   AveOccup                      20640 non-null  float64\n",
      " 6   Latitude                      20640 non-null  float64\n",
      " 7   Longitude                     20640 non-null  float64\n",
      " 8   MedHouseVal                   20640 non-null  float64\n",
      " 9   AveOccup_log                  20640 non-null  float64\n",
      " 10  AveOccup_sqrt                 20640 non-null  float64\n",
      " 11  AveOccup_power                20640 non-null  float64\n",
      " 12  AveOccup_quantile_uniform     20640 non-null  float64\n",
      " 13  AveOccup_quantile_normal      20640 non-null  float64\n",
      " 14  AveBedrms_log                 20640 non-null  float64\n",
      " 15  AveBedrms_sqrt                20640 non-null  float64\n",
      " 16  AveBedrms_power               20640 non-null  float64\n",
      " 17  AveBedrms_quantile_uniform    20640 non-null  float64\n",
      " 18  AveBedrms_quantile_normal     20640 non-null  float64\n",
      " 19  AveRooms_log                  20640 non-null  float64\n",
      " 20  AveRooms_sqrt                 20640 non-null  float64\n",
      " 21  AveRooms_power                20640 non-null  float64\n",
      " 22  AveRooms_quantile_uniform     20640 non-null  float64\n",
      " 23  AveRooms_quantile_normal      20640 non-null  float64\n",
      " 24  MedInc_log                    20640 non-null  float64\n",
      " 25  MedInc_sqrt                   20640 non-null  float64\n",
      " 26  MedInc_power                  20640 non-null  float64\n",
      " 27  MedInc_quantile_uniform       20640 non-null  float64\n",
      " 28  MedInc_quantile_normal        20640 non-null  float64\n",
      " 29  Population_log                20640 non-null  float64\n",
      " 30  Population_sqrt               20640 non-null  float64\n",
      " 31  Population_power              20640 non-null  float64\n",
      " 32  Population_quantile_uniform   20640 non-null  float64\n",
      " 33  Population_quantile_normal    20640 non-null  float64\n",
      " 34  MedHouseVal_log               20640 non-null  float64\n",
      " 35  MedHouseVal_sqrt              20640 non-null  float64\n",
      " 36  MedHouseVal_power             20640 non-null  float64\n",
      " 37  MedHouseVal_quantile_uniform  20640 non-null  float64\n",
      " 38  MedHouseVal_quantile_normal   20640 non-null  float64\n",
      "dtypes: float64(39)\n",
      "memory usage: 6.1 MB\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'MedHouseVal', 'AveOccup_log', 'AveOccup_sqrt', 'AveOccup_power', 'AveOccup_quantile_uniform', 'AveOccup_quantile_normal', 'AveBedrms_log', 'AveBedrms_sqrt', 'AveBedrms_power', 'AveBedrms_quantile_uniform', 'AveBedrms_quantile_normal', 'AveRooms_log', 'AveRooms_sqrt', 'AveRooms_power', 'AveRooms_quantile_uniform', 'AveRooms_quantile_normal', 'MedInc_log', 'MedInc_sqrt', 'MedInc_power', 'MedInc_quantile_uniform', 'MedInc_quantile_normal', 'Population_log', 'Population_sqrt', 'Population_power', 'Population_quantile_uniform', 'Population_quantile_normal', 'MedHouseVal_log', 'MedHouseVal_sqrt', 'MedHouseVal_power', 'MedHouseVal_quantile_uniform', 'MedHouseVal_quantile_normal']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   MedInc           20640 non-null  float64\n",
      " 1   HouseAge         20640 non-null  float64\n",
      " 2   AveRooms         20640 non-null  float64\n",
      " 3   AveBedrms        20640 non-null  float64\n",
      " 4   Population       20640 non-null  float64\n",
      " 5   AveOccup         20640 non-null  float64\n",
      " 6   Latitude         20640 non-null  float64\n",
      " 7   Longitude        20640 non-null  float64\n",
      " 8   MedHouseVal      20640 non-null  float64\n",
      " 9   AveOccup_log     20640 non-null  float64\n",
      " 10  AveBedrms_log    20640 non-null  float64\n",
      " 11  AveRooms_log     20640 non-null  float64\n",
      " 12  MedInc_log       20640 non-null  float64\n",
      " 13  Population_log   20640 non-null  float64\n",
      " 14  MedHouseVal_log  20640 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 2.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   HouseAge     20640 non-null  float64\n",
      " 1   Latitude     20640 non-null  float64\n",
      " 2   Longitude    20640 non-null  float64\n",
      " 3   AveOccup     20640 non-null  float64\n",
      " 4   AveBedrms    20640 non-null  float64\n",
      " 5   AveRooms     20640 non-null  float64\n",
      " 6   MedInc       20640 non-null  float64\n",
      " 7   Population   20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Transform MedHouseVal\n",
    "feature = 'MedHouseVal'\n",
    "\n",
    "# Apply log transformation (using log1p to handle zeros)\n",
    "housing_df[f'{feature}_log'] = np.log1p(housing_df[feature])\n",
    "# Apply square root transformation\n",
    "housing_df[f'{feature}_sqrt'] = np.sqrt(housing_df[feature])\n",
    "# Apply power transformation using Yeo-Johnson (handles positive and negative values)\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "# Fit and transform\n",
    "housing_df[f'{feature}_power'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to uniform distribution\n",
    "transformer = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "housing_df[f'{feature}_quantile_uniform'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Apply quantile transformation to normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "housing_df[f'{feature}_quantile_normal'] = transformer.fit_transform(housing_df[[feature]])\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "\n",
    "axes[0].set_title('Original distribution')\n",
    "axes[0].hist(housing_df[feature], bins=50, edgecolor='black', color='grey')\n",
    "axes[0].set_xlabel(feature)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].set_title('Log-transformed distribution')\n",
    "axes[1].hist(housing_df[f'{feature}_log'], bins=50, edgecolor='black', color='grey')\n",
    "axes[1].set_xlabel(f'{feature}_log')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].set_title('Square root-transformed distribution')\n",
    "axes[2].hist(housing_df[f'{feature}_sqrt'], bins=50, edgecolor='black', color='grey')\n",
    "axes[2].set_xlabel(f'{feature}_sqrt')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "axes[3].set_title('Power-transformed distribution')\n",
    "axes[3].hist(housing_df[f'{feature}_power'], bins=50, edgecolor='black', color='grey')\n",
    "axes[3].set_xlabel(f'{feature}_power')\n",
    "axes[3].set_ylabel('Frequency')\n",
    "\n",
    "axes[4].set_title('Quantile transform (uniform)')\n",
    "axes[4].hist(housing_df[f'{feature}_quantile_uniform'], bins=50, edgecolor='black', color='grey')\n",
    "axes[4].set_xlabel('Uniform [0, 1]')\n",
    "axes[4].set_ylabel('Frequency')\n",
    "\n",
    "axes[5].set_xlabel('Normal distribution')\n",
    "axes[5].set_title('Quantile transform (normal)')\n",
    "axes[5].hist(housing_df[f'{feature}_quantile_normal'], bins=50, edgecolor='black', color='grey')\n",
    "axes[5].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "housing_df.info()\n",
    "column_list = housing_df.columns.tolist()\n",
    "print(column_list)\n",
    "housing_df.drop([#'AveOccup_log',\n",
    "                 'AveOccup_sqrt', \n",
    "                 'AveOccup_power', \n",
    "                 'AveOccup_quantile_uniform',\n",
    "                 'AveOccup_quantile_normal',\n",
    "                 #'AveBedrms_log',\n",
    "                 'AveBedrms_sqrt', \n",
    "                 'AveBedrms_power', \n",
    "                 'AveBedrms_quantile_uniform',\n",
    "                 'AveBedrms_quantile_normal',\n",
    "                 #'AveRooms_log',\n",
    "                 'AveRooms_sqrt', \n",
    "                 'AveRooms_power', \n",
    "                 'AveRooms_quantile_uniform',\n",
    "                 'AveRooms_quantile_normal',\n",
    "                 #'Population_log',\n",
    "                 'Population_sqrt', \n",
    "                 'Population_power', \n",
    "                 'Population_quantile_uniform',\n",
    "                 'Population_quantile_normal',\n",
    "                 #'MedInc_log',\n",
    "                 'MedInc_sqrt', \n",
    "                 'MedInc_power', \n",
    "                 'MedInc_quantile_uniform', \n",
    "                 'MedInc_quantile_normal',\n",
    "                 #'MedHouseVal_log',\n",
    "                 'MedHouseVal_sqrt',\n",
    "                 'MedHouseVal_power', \n",
    "                 'MedHouseVal_quantile_uniform',\n",
    "                 'MedHouseVal_quantile_normal'], axis=1, inplace=True)\n",
    "\n",
    "housing_df.info()\n",
    "\n",
    "housing_df.drop(['MedInc',  'AveRooms', 'AveBedrms', 'Population', 'AveOccup','MedHouseVal'], axis=1, inplace=True)\n",
    "\n",
    "housing_df.rename(columns={'MedInc_log':'MedInc', 'AveRooms_log': 'AveRooms','AveOccup_log':'AveOccup','AveBedrms_log':'AveBedrms', 'Population_log':'Population','MedHouseVal_log':'MedHouseVal'}, inplace=True)\n",
    "housing_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a82f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:12.651003Z",
     "iopub.status.busy": "2025-11-20T19:47:12.650774Z",
     "iopub.status.idle": "2025-11-20T19:47:12.775360Z",
     "shell.execute_reply": "2025-11-20T19:47:12.774587Z"
    },
    "papermill": {
     "duration": 0.130448,
     "end_time": "2025-11-20T19:47:12.775895",
     "exception": false,
     "start_time": "2025-11-20T19:47:12.645447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binned features added:\n",
      "\n",
      "Encoded binned features:\n",
      "Original features replaced with binned encoded versions:\n",
      "   Latitude  Longitude  AveOccup  AveBedrms  AveRooms    MedInc  Population  \\\n",
      "0     37.88    -122.23  1.268511   0.704982  2.077455  2.232720    5.777652   \n",
      "1     37.86    -122.22  1.134572   0.678988  1.979364  2.230165    7.784057   \n",
      "2     37.85    -122.24  1.335596   0.729212  2.228738  2.111110    6.208590   \n",
      "3     37.85    -122.25  1.266369   0.729025  1.919471  1.893579    6.326149   \n",
      "4     37.85    -122.25  1.157342   0.732888  1.985385  1.578195    6.338594   \n",
      "\n",
      "   MedHouseVal  HouseAge  \n",
      "0     1.709464         4  \n",
      "1     1.522790         2  \n",
      "2     1.508733         4  \n",
      "3     1.484555         4  \n",
      "4     1.486592         4  \n",
      "\n",
      "Dataframe info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Latitude     20640 non-null  float64\n",
      " 1   Longitude    20640 non-null  float64\n",
      " 2   AveOccup     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   AveRooms     20640 non-null  float64\n",
      " 5   MedInc       20640 non-null  float64\n",
      " 6   Population   20640 non-null  float64\n",
      " 7   MedHouseVal  20640 non-null  float64\n",
      " 8   HouseAge     20640 non-null  int8   \n",
      "dtypes: float64(8), int8(1)\n",
      "memory usage: 1.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Create bins/categories from continuous variables\n",
    "\n",
    "# Bin HouseAge into age groups\n",
    "housing_df['HouseAge_binned'] = pd.cut(housing_df['HouseAge'], \n",
    "                                        bins=[0, 10, 20, 30, 40, 52], \n",
    "                                        labels=['1-10', '11-20', '21-30', '31-40', '41-52'])\n",
    "\n",
    "# Bin Latitude into geographic regions\n",
    "#housing_df['Latitude_binned'] = pd.cut(housing_df['Latitude'], bins=5, labels=['South', 'South-Central', 'Central', 'North-Central', 'North'])\n",
    "\n",
    "# Bin Longitude into geographic regions\n",
    "#housing_df['Longitude_binned'] = pd.cut(housing_df['Longitude'], bins=5, labels=['Far West', 'West', 'Central', 'East', 'Far East'])\n",
    "\n",
    "# Bin MedInc into income brackets\n",
    "#housing_df['MedInc_binned'] = pd.cut(housing_df['MedInc'], bins=[0, 2, 4, 6, 8, 16], labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Convert binned columns to numeric codes for model compatibility\n",
    "housing_df['HouseAge_binned_encoded'] = pd.Categorical(housing_df['HouseAge_binned']).codes\n",
    "#housing_df['Latitude_binned_encoded'] = pd.Categorical(housing_df['Latitude_binned']).codes\n",
    "#housing_df['Longitude_binned_encoded'] = pd.Categorical(housing_df['Longitude_binned']).codes\n",
    "#housing_df['MedInc_binned_encoded'] = pd.Categorical(housing_df['MedInc_binned']).codes\n",
    "\n",
    "# Visualize the binned features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# HouseAge binned\n",
    "axes[0, 0].bar(housing_df['HouseAge_binned'].value_counts().index, \n",
    "               housing_df['HouseAge_binned'].value_counts().values, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('HouseAge Distribution (Binned)')\n",
    "axes[0, 0].set_xlabel('Age Group')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Latitude binned\n",
    "#axes[0, 1].bar(housing_df['Latitude_binned'].value_counts().index, \n",
    " #              housing_df['Latitude_binned'].value_counts().values, color='lightcoral', edgecolor='black')\n",
    "#axes[0, 1].set_title('Latitude Distribution (Binned)')\n",
    "#axes[0, 1].set_xlabel('Region')\n",
    "#axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Longitude binned\n",
    "#axes[1, 0].bar(housing_df['Longitude_binned'].value_counts().index, \n",
    " #             housing_df['Longitude_binned'].value_counts().values, color='lightgreen', edgecolor='black')\n",
    "#axes[1, 0].set_title('Longitude Distribution (Binned)')\n",
    "#axes[1, 0].set_xlabel('Region')\n",
    "#axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# MedInc binned\n",
    "#axes[1, 1].bar(housing_df['MedInc_binned'].value_counts().index, \n",
    "            #   housing_df['MedInc_binned'].value_counts().values, color='gold', edgecolor='black')\n",
    "#axes[1, 1].set_title('MedInc Distribution (Binned)')\n",
    "#axes[1, 1].set_xlabel('Income Bracket')\n",
    "#axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the binned dataframe info\n",
    "print(\"\\nBinned features added:\")\n",
    "#print(housing_df[['HouseAge_binned', 'Latitude_binned', 'Longitude_binned', 'MedInc_binned']].head(10))\n",
    "print(\"\\nEncoded binned features:\")\n",
    "#print(housing_df[['HouseAge_binned_encoded', 'Latitude_binned_encoded', 'Longitude_binned_encoded', 'MedInc_binned_encoded']].head(10))\n",
    "\n",
    "# Replace original features with binned encoded versions\n",
    "housing_df.drop(['HouseAge', \n",
    "                 #'Latitude', \n",
    "                 #'Longitude', \n",
    "                 #'MedInc', \n",
    "                 'HouseAge_binned',\n",
    "                 #'Latitude_binned', \n",
    "                 #'Longitude_binned'\n",
    "                 #'MedInc_binned'\n",
    "                 ], \n",
    "                axis=1, inplace=True)\n",
    "\n",
    "housing_df.rename(columns={\n",
    "    'HouseAge_binned_encoded': 'HouseAge',\n",
    "    #'Latitude_binned_encoded': 'Latitude',\n",
    "    #'Longitude_binned_encoded': 'Longitude'\n",
    "    #'MedInc_binned_encoded': 'MedInc'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Original features replaced with binned encoded versions:\")\n",
    "print(housing_df.head())\n",
    "print(\"\\nDataframe info:\")\n",
    "print(housing_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ddb17f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:12.786533Z",
     "iopub.status.busy": "2025-11-20T19:47:12.786299Z",
     "iopub.status.idle": "2025-11-20T19:47:40.947088Z",
     "shell.execute_reply": "2025-11-20T19:47:40.946248Z"
    },
    "papermill": {
     "duration": 28.167479,
     "end_time": "2025-11-20T19:47:40.947847",
     "exception": false,
     "start_time": "2025-11-20T19:47:12.780368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created:\n",
      "  - rooms_per_household: AveRooms / Population\n",
      "  - bedrooms_per_room: AveBedrms / AveRooms\n",
      "  - occupancy_efficiency: Population / AveOccup\n",
      "  - income_population_interaction: MedInc  Population\n",
      "  - room_quality_index: (AveRooms  AveBedrms) / (AveOccup + 1)\n",
      "\n",
      "First few rows of interaction features:\n",
      "   rooms_per_household  bedrooms_per_room  occupancy_efficiency  \\\n",
      "0             0.021690           0.146591                 126.0   \n",
      "1             0.002598           0.155797                1138.0   \n",
      "2             0.016710           0.129516                 177.0   \n",
      "3             0.010425           0.184458                 219.0   \n",
      "4             0.011118           0.172096                 259.0   \n",
      "5             0.011529           0.231774                 193.0   \n",
      "6             0.004508           0.192899                 514.0   \n",
      "7             0.004147           0.221327                 647.0   \n",
      "8             0.003561           0.260274                 595.0   \n",
      "9             0.003205           0.199211                 714.0   \n",
      "\n",
      "   income_population_interaction  room_quality_index  \n",
      "0                      2680.7144            2.011054  \n",
      "1                     19931.6614            1.949528  \n",
      "2                      3599.6704            2.339890  \n",
      "3                      3148.8498            1.759431  \n",
      "4                      2173.1030            2.134610  \n",
      "5                      1667.1984            1.673652  \n",
      "6                      4003.0554            1.499815  \n",
      "7                      3609.8400            1.826996  \n",
      "8                      2508.9624            1.585557  \n",
      "9                      5725.0512            1.551526  \n",
      "\n",
      "Dataframe info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Latitude                       20640 non-null  float64\n",
      " 1   Longitude                      20640 non-null  float64\n",
      " 2   AveOccup                       20640 non-null  float64\n",
      " 3   AveBedrms                      20640 non-null  float64\n",
      " 4   AveRooms                       20640 non-null  float64\n",
      " 5   MedInc                         20640 non-null  float64\n",
      " 6   Population                     20640 non-null  float64\n",
      " 7   MedHouseVal                    20640 non-null  float64\n",
      " 8   HouseAge                       20640 non-null  int8   \n",
      " 9   rooms_per_household            20640 non-null  float64\n",
      " 10  bedrooms_per_room              20640 non-null  float64\n",
      " 11  occupancy_efficiency           20640 non-null  float64\n",
      " 12  income_population_interaction  20640 non-null  float64\n",
      " 13  room_quality_index             20640 non-null  float64\n",
      "dtypes: float64(13), int8(1)\n",
      "memory usage: 2.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create interaction features\n",
    "\n",
    "# Reload the original features to create interactions\n",
    "# (We need the original Population and AveRooms values for interactions)\n",
    "original_housing_df_temp = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "\n",
    "# Feature 1: Rooms per household (total rooms / population)\n",
    "# This indicates room density relative to population\n",
    "housing_df['rooms_per_household'] = original_housing_df_temp['AveRooms'] / original_housing_df_temp['Population']\n",
    "\n",
    "# Feature 2: Bedrooms per room (bedrooms / rooms)\n",
    "# This indicates the proportion of rooms that are bedrooms\n",
    "housing_df['bedrooms_per_room'] = original_housing_df_temp['AveBedrms'] / original_housing_df_temp['AveRooms']\n",
    "\n",
    "# Feature 3: Occupancy efficiency (population / occupancy)\n",
    "# This indicates how many people per occupied unit\n",
    "housing_df['occupancy_efficiency'] = original_housing_df_temp['Population'] / original_housing_df_temp['AveOccup']\n",
    "\n",
    "# Feature 4: Income  Population interaction (scaled income with population size)\n",
    "# Higher income areas with more population might have different value patterns\n",
    "housing_df['income_population_interaction'] = original_housing_df_temp['MedInc'] * original_housing_df_temp['Population']\n",
    "\n",
    "# Feature 5: Room quality index (rooms + bedrooms interaction normalized)\n",
    "# Combines room count and bedroom count as a proxy for housing quality\n",
    "housing_df['room_quality_index'] = (original_housing_df_temp['AveRooms'] * original_housing_df_temp['AveBedrms']) / (original_housing_df_temp['AveOccup'] + 1)\n",
    "\n",
    "# Visualize the new interaction features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# rooms_per_household\n",
    "sns.histplot(housing_df['rooms_per_household'], kde=True, color='skyblue', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Rooms per Household')\n",
    "axes[0, 0].set_xlabel('Rooms per Household')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# bedrooms_per_room\n",
    "sns.histplot(housing_df['bedrooms_per_room'], kde=True, color='lightcoral', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Bedrooms per Room')\n",
    "axes[0, 1].set_xlabel('Bedrooms per Room')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# occupancy_efficiency\n",
    "sns.histplot(housing_df['occupancy_efficiency'], kde=True, color='lightgreen', ax=axes[0, 2])\n",
    "axes[0, 2].set_title('Occupancy Efficiency')\n",
    "axes[0, 2].set_xlabel('People per Occupied Unit')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# income_population_interaction\n",
    "sns.histplot(housing_df['income_population_interaction'], kde=True, color='gold', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Income  Population Interaction')\n",
    "axes[1, 0].set_xlabel('Interaction Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# room_quality_index\n",
    "sns.histplot(housing_df['room_quality_index'], kde=True, color='plum', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Room Quality Index')\n",
    "axes[1, 1].set_xlabel('Quality Index')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Correlation with target\n",
    "ax = axes[1, 2]\n",
    "interaction_cols = ['rooms_per_household', 'bedrooms_per_room', 'occupancy_efficiency', \n",
    "                   'income_population_interaction', 'room_quality_index']\n",
    "correlations = [housing_df[col].corr(housing_df['MedHouseVal']) for col in interaction_cols]\n",
    "ax.barh(interaction_cols, correlations, color='steelblue')\n",
    "ax.set_title('Interaction Features Correlation with MedHouseVal')\n",
    "ax.set_xlabel('Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interaction features created:\")\n",
    "print(f\"  - rooms_per_household: AveRooms / Population\")\n",
    "print(f\"  - bedrooms_per_room: AveBedrms / AveRooms\")\n",
    "print(f\"  - occupancy_efficiency: Population / AveOccup\")\n",
    "print(f\"  - income_population_interaction: MedInc  Population\")\n",
    "print(f\"  - room_quality_index: (AveRooms  AveBedrms) / (AveOccup + 1)\")\n",
    "print(\"\\nFirst few rows of interaction features:\")\n",
    "print(housing_df[interaction_cols].head(10))\n",
    "print(\"\\nDataframe info:\")\n",
    "print(housing_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b85627",
   "metadata": {
    "papermill": {
     "duration": 0.004663,
     "end_time": "2025-11-20T19:47:40.957755",
     "exception": false,
     "start_time": "2025-11-20T19:47:40.953092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 3: Apply your second feature engineering technique\n",
    "\n",
    "**Example approaches**:\n",
    "- Scale features to similar ranges\n",
    "- Encode any categorical variables you created\n",
    "- Create aggregate statistics by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62981c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:40.968772Z",
     "iopub.status.busy": "2025-11-20T19:47:40.968527Z",
     "iopub.status.idle": "2025-11-20T19:47:41.266641Z",
     "shell.execute_reply": "2025-11-20T19:47:41.265884Z"
    },
    "papermill": {
     "duration": 0.304309,
     "end_time": "2025-11-20T19:47:41.267186",
     "exception": false,
     "start_time": "2025-11-20T19:47:40.962877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE SCALING COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Before Scaling (Original Features):\n",
      "           Latitude     Longitude      AveOccup     AveBedrms      AveRooms  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean      35.631861   -119.569704      1.351645      0.732035      1.828722   \n",
      "std        2.135952      2.003532      0.207530      0.105412      0.231938   \n",
      "min       32.540000   -124.350000      0.526093      0.287682      0.613104   \n",
      "25%       33.930000   -121.800000      1.232485      0.696182      1.693911   \n",
      "50%       34.260000   -118.490000      1.339757      0.717245      1.829236   \n",
      "75%       37.710000   -118.010000      1.454481      0.741712      1.953365   \n",
      "max       41.950000   -114.310000      7.126355      3.557251      4.962209   \n",
      "\n",
      "             MedInc    Population   MedHouseVal      HouseAge  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       1.516995      7.025503      1.056146      2.267006   \n",
      "std        0.358677      0.736238      0.356212      1.218777   \n",
      "min        0.405398      1.386294      0.139753      0.000000   \n",
      "25%        1.270715      6.669498      0.786638      1.000000   \n",
      "50%        1.511781      7.062192      1.028547      2.000000   \n",
      "75%        1.748025      7.453562      1.293973      3.000000   \n",
      "max        2.772595     10.482430      1.791761      4.000000   \n",
      "\n",
      "       rooms_per_household  bedrooms_per_room  occupancy_efficiency  \\\n",
      "count         20640.000000       20640.000000          20640.000000   \n",
      "mean              0.008842           0.213075            499.539680   \n",
      "std               0.056555           0.058023            382.329753   \n",
      "min               0.000148           0.100000              1.000000   \n",
      "25%               0.002837           0.175426            280.000000   \n",
      "50%               0.004440           0.203181            409.000000   \n",
      "75%               0.006925           0.239834            605.000000   \n",
      "max               4.730303           1.000000           6082.000000   \n",
      "\n",
      "       income_population_interaction  room_quality_index  \n",
      "count                   20640.000000        20640.000000  \n",
      "mean                     5527.951974            1.878182  \n",
      "std                      5590.224782           12.598677  \n",
      "min                         1.608000            0.002121  \n",
      "25%                      2462.718700            1.185450  \n",
      "50%                      4149.025900            1.470214  \n",
      "75%                      6713.335575            1.735695  \n",
      "max                    120829.553400         1327.932026  \n",
      "\n",
      "======================================================================\n",
      "\n",
      "After Scaling (Standardized Features):\n",
      "           Latitude     Longitude      AveOccup     AveBedrms      AveRooms  \\\n",
      "count  2.064000e+04  2.064000e+04  2.064000e+04  2.064000e+04  2.064000e+04   \n",
      "mean  -1.079584e-15 -8.526513e-15 -8.702771e-16 -1.542263e-16 -8.372286e-16   \n",
      "std    1.000024e+00  1.000024e+00  1.000024e+00  1.000024e+00  1.000024e+00   \n",
      "min   -1.447568e+00 -2.385992e+00 -3.978076e+00 -4.215505e+00 -5.241251e+00   \n",
      "25%   -7.967887e-01 -1.113209e+00 -5.741942e-01 -3.401299e-01 -5.812535e-01   \n",
      "50%   -6.422871e-01  5.389137e-01 -5.728282e-02 -1.403120e-01  2.216298e-03   \n",
      "75%    9.729566e-01  7.784964e-01  4.955369e-01  9.180164e-02  5.374093e-01   \n",
      "max    2.958068e+00  2.625280e+00  2.782653e+01  2.680238e+01  1.351032e+01   \n",
      "\n",
      "             MedInc    Population      HouseAge  rooms_per_household  \\\n",
      "count  2.064000e+04  2.064000e+04  2.064000e+04         2.064000e+04   \n",
      "mean  -1.872748e-16 -9.528984e-16  1.101617e-16        -2.513063e-17   \n",
      "std    1.000024e+00  1.000024e+00  1.000024e+00         1.000024e+00   \n",
      "min   -3.099229e+00 -7.659682e+00 -1.860111e+00        -1.537369e-01   \n",
      "25%   -6.866501e-01 -4.835575e-01 -1.039597e+00        -1.061822e-01   \n",
      "50%   -1.453727e-02  4.983434e-02 -2.190821e-01        -7.784675e-02   \n",
      "75%    6.441326e-01  5.814287e-01  6.014324e-01        -3.390605e-02   \n",
      "max    3.500723e+00  4.695510e+00  1.421947e+00         8.348645e+01   \n",
      "\n",
      "       bedrooms_per_room  occupancy_efficiency  income_population_interaction  \\\n",
      "count       2.064000e+04          2.064000e+04                   2.064000e+04   \n",
      "mean       -4.351386e-16          6.334296e-17                  -1.514723e-17   \n",
      "std         1.000024e+00          1.000024e+00                   1.000024e+00   \n",
      "min        -1.948819e+00         -1.303984e+00                  -9.885967e-01   \n",
      "25%        -6.488732e-01         -5.742294e-01                  -5.483335e-01   \n",
      "50%        -1.705187e-01         -2.368162e-01                  -2.466734e-01   \n",
      "75%         4.612029e-01          2.758427e-01                   2.120509e-01   \n",
      "max         1.356252e+01          1.460152e+01                   2.062607e+01   \n",
      "\n",
      "       room_quality_index   MedHouseVal  \n",
      "count        2.064000e+04  20640.000000  \n",
      "mean         2.754042e-18      1.056146  \n",
      "std          1.000024e+00      0.356212  \n",
      "min         -1.489130e-01      0.139753  \n",
      "25%         -5.498584e-02      0.786638  \n",
      "50%         -3.238258e-02      1.028547  \n",
      "75%         -1.130992e-02      1.293973  \n",
      "max          1.052560e+02      1.791761  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling Summary:\n",
      "  - Scaling method: StandardScaler (z-score normalization)\n",
      "  - Mean of scaled features: ~0\n",
      "  - Standard deviation of scaled features: ~1\n",
      "  - Shape of engineered dataset: (20640, 14)\n",
      "\n",
      "Scaled dataframe info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Latitude                       20640 non-null  float64\n",
      " 1   Longitude                      20640 non-null  float64\n",
      " 2   AveOccup                       20640 non-null  float64\n",
      " 3   AveBedrms                      20640 non-null  float64\n",
      " 4   AveRooms                       20640 non-null  float64\n",
      " 5   MedInc                         20640 non-null  float64\n",
      " 6   Population                     20640 non-null  float64\n",
      " 7   HouseAge                       20640 non-null  float64\n",
      " 8   rooms_per_household            20640 non-null  float64\n",
      " 9   bedrooms_per_room              20640 non-null  float64\n",
      " 10  occupancy_efficiency           20640 non-null  float64\n",
      " 11  income_population_interaction  20640 non-null  float64\n",
      " 12  room_quality_index             20640 non-null  float64\n",
      " 13  MedHouseVal                    20640 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 2.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Scale features to similar ranges\n",
    "\n",
    "# Separate target variable from features\n",
    "X = housing_df.drop('MedHouseVal', axis=1)\n",
    "y = housing_df['MedHouseVal']\n",
    "\n",
    "# Create StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert scaled features back to DataFrame to maintain column names\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Add target variable back\n",
    "housing_df_scaled = X_scaled_df.copy()\n",
    "housing_df_scaled['MedHouseVal'] = y.values\n",
    "\n",
    "# Display statistics before and after scaling\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE SCALING COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nBefore Scaling (Original Features):\")\n",
    "print(housing_df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nAfter Scaling (Standardized Features):\")\n",
    "print(housing_df_scaled.describe())\n",
    "\n",
    "# Visualize the difference between original and scaled features\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Select a few key features to visualize\n",
    "key_features = ['MedInc', 'Population', 'rooms_per_household', 'room_quality_index']\n",
    "\n",
    "# Plot original features\n",
    "for feature in key_features:\n",
    "    axes[0].hist(housing_df[feature], alpha=0.6, label=feature, bins=30, edgecolor='black')\n",
    "axes[0].set_title('Original Features (Different Scales)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot scaled features\n",
    "for feature in key_features:\n",
    "    axes[1].hist(housing_df_scaled[feature], alpha=0.6, label=feature, bins=30, edgecolor='black')\n",
    "axes[1].set_title('Scaled Features (Standardized - Mean=0, Std=1)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Standardized Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Update housing_df with scaled features\n",
    "housing_df = housing_df_scaled\n",
    "\n",
    "print(\"\\nScaling Summary:\")\n",
    "print(f\"  - Scaling method: StandardScaler (z-score normalization)\")\n",
    "print(f\"  - Mean of scaled features: ~0\")\n",
    "print(f\"  - Standard deviation of scaled features: ~1\")\n",
    "print(f\"  - Shape of engineered dataset: {housing_df.shape}\")\n",
    "print(f\"\\nScaled dataframe info:\")\n",
    "print(housing_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65965541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:41.278322Z",
     "iopub.status.busy": "2025-11-20T19:47:41.278084Z",
     "iopub.status.idle": "2025-11-20T19:47:41.354545Z",
     "shell.execute_reply": "2025-11-20T19:47:41.353839Z"
    },
    "papermill": {
     "duration": 0.083173,
     "end_time": "2025-11-20T19:47:41.355142",
     "exception": false,
     "start_time": "2025-11-20T19:47:41.271969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CATEGORICAL VARIABLE ENCODING\n",
      "======================================================================\n",
      "\n",
      "Dataset Info (before encoding):\n",
      "Latitude                         float64\n",
      "Longitude                        float64\n",
      "AveOccup                         float64\n",
      "AveBedrms                        float64\n",
      "AveRooms                         float64\n",
      "MedInc                           float64\n",
      "Population                       float64\n",
      "HouseAge                         float64\n",
      "rooms_per_household              float64\n",
      "bedrooms_per_room                float64\n",
      "occupancy_efficiency             float64\n",
      "income_population_interaction    float64\n",
      "room_quality_index               float64\n",
      "MedHouseVal                      float64\n",
      "dtype: object\n",
      "\n",
      "======================================================================\n",
      "ENCODING SCHEME FOR BINNED FEATURES\n",
      "======================================================================\n",
      "\n",
      "HouseAge Binning Encoding:\n",
      "  Original bins: [1-10, 11-20, 21-30, 31-40, 41-52]\n",
      "  Encoded values: [0, 1, 2, 3, 4]\n",
      "  (Ordinal encoding preserves the natural ordering of age groups)\n",
      "\n",
      "Sample of encoded HouseAge values:\n",
      "\n",
      "Original HouseAge -> Binned -> Encoded\n",
      "     41 ->  41-52 -> 4\n",
      "     21 ->  21-30 -> 2\n",
      "     52 ->  41-52 -> 4\n",
      "     52 ->  41-52 -> 4\n",
      "     52 ->  41-52 -> 4\n",
      "     52 ->  41-52 -> 4\n",
      "     52 ->  41-52 -> 4\n",
      "     52 ->  41-52 -> 4\n",
      "     42 ->  41-52 -> 4\n",
      "     52 ->  41-52 -> 4\n",
      "\n",
      "Encoding Summary:\n",
      "  - Encoding Type: Ordinal Encoding (for binned HouseAge)\n",
      "  - Reason: HouseAge bins have a natural ordering (older  newer)\n",
      "  - All other features: Already numeric (no encoding needed)\n",
      "  - Total features in engineered dataset: 14\n",
      "\n",
      "Final Engineered Dataset:\n",
      "   Latitude  Longitude  AveOccup  AveBedrms  AveRooms    MedInc  Population  \\\n",
      "0  1.052548  -1.327835 -0.400594  -0.256650  1.072436  1.995505   -1.694943   \n",
      "1  1.043185  -1.322844 -1.046006  -0.503251  0.649505  1.988380    1.030337   \n",
      "2  1.038503  -1.332827 -0.077335  -0.026779  1.724704  1.656444   -1.109604   \n",
      "3  1.038503  -1.337818 -0.410919  -0.028550  0.391271  1.049948   -0.949925   \n",
      "4  1.038503  -1.337818 -0.936282   0.008089  0.675467  0.170631   -0.933021   \n",
      "5  1.038503  -1.337818 -0.999660   0.110314 -0.334136  0.278184   -1.357797   \n",
      "6  1.033821  -1.337818 -1.017329  -0.602484 -0.208581  0.060856   -0.036664   \n",
      "7  1.033821  -1.337818 -1.571997  -0.080107 -0.307378 -0.281992    0.039318   \n",
      "8  1.033821  -1.342809 -1.176284   0.173331 -0.699022 -1.092751    0.095611   \n",
      "9  1.033821  -1.337818 -0.950234  -0.415540 -0.180557  0.080000    0.437094   \n",
      "\n",
      "   HouseAge  rooms_per_household  bedrooms_per_room  occupancy_efficiency  \\\n",
      "0  1.421947             0.227178          -1.145833             -0.977033   \n",
      "1 -0.219082            -0.110407          -0.987175              1.669961   \n",
      "2  1.421947             0.139122          -1.440115             -0.843637   \n",
      "3  1.421947             0.027996          -0.493194             -0.733781   \n",
      "4  1.421947             0.040249          -0.706259             -0.629157   \n",
      "5  1.421947             0.047519           0.322276             -0.801787   \n",
      "6  1.421947            -0.076634          -0.347714              0.037823   \n",
      "7  1.421947            -0.083028           0.142236              0.385698   \n",
      "8  1.421947            -0.093388           0.813474              0.249687   \n",
      "9  1.421947            -0.099681          -0.238934              0.560944   \n",
      "\n",
      "   income_population_interaction  room_quality_index  MedHouseVal  \n",
      "0                      -0.509337            0.010547     1.709464  \n",
      "1                       2.576651            0.005663     1.522790  \n",
      "2                      -0.344946            0.036648     1.508733  \n",
      "3                      -0.425593           -0.009426     1.484555  \n",
      "4                      -0.600142            0.020354     1.486592  \n",
      "5                      -0.690643           -0.016235     1.307522  \n",
      "6                      -0.272786           -0.030033     1.384292  \n",
      "7                      -0.343127           -0.004063     1.227885  \n",
      "8                      -0.540061           -0.023227     1.183872  \n",
      "9                       0.035259           -0.025928     1.283985  \n",
      "\n",
      "Dataset Statistics:\n",
      "  Shape: (20640, 14)\n",
      "  No missing values: True\n",
      "  All features are numeric: True\n"
     ]
    }
   ],
   "source": [
    "# Encode any categorical variables you created\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CATEGORICAL VARIABLE ENCODING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if we have any categorical features in the dataset\n",
    "print(\"\\nDataset Info (before encoding):\")\n",
    "print(housing_df.dtypes)\n",
    "\n",
    "# Since we've already encoded HouseAge during binning (it's now numeric),\n",
    "# let's verify it and document the encoding scheme\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ENCODING SCHEME FOR BINNED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nHouseAge Binning Encoding:\")\n",
    "print(\"  Original bins: [1-10, 11-20, 21-30, 31-40, 41-52]\")\n",
    "print(\"  Encoded values: [0, 1, 2, 3, 4]\")\n",
    "print(\"  (Ordinal encoding preserves the natural ordering of age groups)\")\n",
    "\n",
    "# Display sample of encoded features\n",
    "print(\"\\nSample of encoded HouseAge values:\")\n",
    "original_housing_df_temp = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "house_age_bins = pd.cut(original_housing_df_temp['HouseAge'], \n",
    "                        bins=[0, 10, 20, 30, 40, 52], \n",
    "                        labels=['1-10', '11-20', '21-30', '31-40', '41-52'])\n",
    "house_age_encoded = pd.Categorical(house_age_bins).codes\n",
    "\n",
    "print(\"\\nOriginal HouseAge -> Binned -> Encoded\")\n",
    "for i in range(10):\n",
    "    print(f\"  {original_housing_df_temp['HouseAge'].iloc[i]:5.0f} -> {house_age_bins.iloc[i]:>6} -> {house_age_encoded[i]}\")\n",
    "\n",
    "print(\"\\nEncoding Summary:\")\n",
    "print(\"  - Encoding Type: Ordinal Encoding (for binned HouseAge)\")\n",
    "print(\"  - Reason: HouseAge bins have a natural ordering (older  newer)\")\n",
    "print(\"  - All other features: Already numeric (no encoding needed)\")\n",
    "print(f\"  - Total features in engineered dataset: {housing_df.shape[1]}\")\n",
    "\n",
    "print(\"\\nFinal Engineered Dataset:\")\n",
    "print(housing_df.head(10))\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"  Shape: {housing_df.shape}\")\n",
    "print(f\"  No missing values: {housing_df.isnull().sum().sum() == 0}\")\n",
    "print(f\"  All features are numeric: {housing_df.select_dtypes(include=[np.number]).shape[1] == housing_df.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3e2661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:41.366217Z",
     "iopub.status.busy": "2025-11-20T19:47:41.365984Z",
     "iopub.status.idle": "2025-11-20T19:47:41.680488Z",
     "shell.execute_reply": "2025-11-20T19:47:41.679722Z"
    },
    "papermill": {
     "duration": 0.321037,
     "end_time": "2025-11-20T19:47:41.681092",
     "exception": false,
     "start_time": "2025-11-20T19:47:41.360055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. MEDIAN HOUSE VALUE BY INCOME GROUP\n",
      "----------------------------------------------------------------------\n",
      "                  count      mean       std      min      max\n",
      "income_group                                                 \n",
      "Low Income         5160  1.229929  0.705237  0.14999  5.00001\n",
      "Lower-Mid Income   5160  1.718111  0.820389  0.22500  5.00001\n",
      "Upper-Mid Income   5160  2.158627  0.924747  0.14999  5.00001\n",
      "High Income        5160  3.167567  1.122158  0.47500  5.00001\n",
      "\n",
      "Insight: Higher income areas have significantly higher house values\n",
      "\n",
      "2. MEDIAN HOUSE VALUE BY POPULATION DENSITY\n",
      "----------------------------------------------------------------------\n",
      "                  count      mean       std      min      max\n",
      "population_group                                             \n",
      "Sparse             5164  2.117733  1.286290  0.14999  5.00001\n",
      "Low Density        5161  2.124931  1.199842  0.26600  5.00001\n",
      "Medium Density     5159  2.031766  1.114453  0.22500  5.00001\n",
      "High Density       5156  1.999693  0.989347  0.22500  5.00001\n",
      "\n",
      "Insight: Population density patterns show impact on house values\n",
      "\n",
      "3. MEDIAN HOUSE VALUE BY HOUSE AGE\n",
      "----------------------------------------------------------------------\n",
      "                  count      mean       std      min      max\n",
      "age_group                                                    \n",
      "Very New (1-10)    1569  2.002633  1.030705  0.22500  5.00001\n",
      "New (11-20)        4724  1.911816  1.018373  0.14999  5.00001\n",
      "Medium (21-30)     4852  2.068016  1.150113  0.25000  5.00001\n",
      "Old (31-40)        5617  2.066622  1.165136  0.14999  5.00001\n",
      "Very Old (41-52)   3878  2.289650  1.301391  0.14999  5.00001\n",
      "\n",
      "Insight: Newer houses tend to have higher values\n",
      "\n",
      "4. MEDIAN HOUSE VALUE BY INCOME AND AGE GROUP\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   count      mean\n",
      "income_group     age_group                        \n",
      "Low Income       Very New (1-10)     184  1.285489\n",
      "                 New (11-20)        1051  1.149781\n",
      "                 Medium (21-30)     1236  1.233269\n",
      "                 Old (31-40)        1445  1.204337\n",
      "                 Very Old (41-52)   1244  1.315831\n",
      "Lower-Mid Income Very New (1-10)     307  1.438896\n",
      "                 New (11-20)        1138  1.511480\n",
      "                 Medium (21-30)     1275  1.714369\n",
      "                 Old (31-40)        1386  1.688218\n",
      "                 Very Old (41-52)   1054  2.066370\n",
      "Upper-Mid Income Very New (1-10)     470  1.706768\n",
      "                 New (11-20)        1151  1.886127\n",
      "                 Medium (21-30)     1078  2.162141\n",
      "                 Old (31-40)        1541  2.159593\n",
      "                 Very Old (41-52)    920  2.724652\n",
      "High Income      Very New (1-10)     608  2.733024\n",
      "                 New (11-20)        1384  2.841043\n",
      "                 Medium (21-30)     1263  3.161587\n",
      "                 Old (31-40)        1245  3.373609\n",
      "                 Very Old (41-52)    660  3.875356\n",
      "\n",
      "5. CREATING GROUP-BASED AGGREGATE FEATURES\n",
      "----------------------------------------------------------------------\n",
      "New aggregate features added:\n",
      "  - income_group_mean: Mean house value for each income group\n",
      "  - population_group_mean: Mean house value for each population density group\n",
      "  - age_group_mean: Mean house value for each age group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274128/3499724310.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  income_agg = original_with_groups.groupby('income_group')['MedHouseVal'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
      "/tmp/ipykernel_274128/3499724310.py:32: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  pop_agg = original_with_groups.groupby('population_group')['MedHouseVal'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
      "/tmp/ipykernel_274128/3499724310.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  age_agg = original_with_groups.groupby('age_group')['MedHouseVal'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
      "/tmp/ipykernel_274128/3499724310.py:46: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  income_age_agg = original_with_groups.groupby(['income_group', 'age_group'])['MedHouseVal'].agg(['count', 'mean'])\n",
      "/tmp/ipykernel_274128/3499724310.py:54: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  income_mean = original_with_groups.groupby('income_group')['MedHouseVal'].transform('mean')\n",
      "/tmp/ipykernel_274128/3499724310.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  pop_mean = original_with_groups.groupby('population_group')['MedHouseVal'].transform('mean')\n",
      "/tmp/ipykernel_274128/3499724310.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  age_mean = original_with_groups.groupby('age_group')['MedHouseVal'].transform('mean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated engineered dataset with aggregate features:\n",
      "  Shape: (20640, 17)\n",
      "  New columns: -1 aggregate features added\n",
      "\n",
      "First few rows:\n",
      "   income_group_mean  population_group_mean  age_group_mean  MedHouseVal\n",
      "0           3.167567               2.117733        2.289650     1.709464\n",
      "1           3.167567               1.999693        2.068016     1.522790\n",
      "2           3.167567               2.117733        2.289650     1.508733\n",
      "3           3.167567               2.117733        2.289650     1.484555\n",
      "4           2.158627               2.117733        2.289650     1.486592\n",
      "5           2.158627               2.117733        2.289650     1.307522\n",
      "6           2.158627               2.124931        2.289650     1.384292\n",
      "7           1.718111               2.124931        2.289650     1.227885\n",
      "8           1.229929               2.031766        2.289650     1.183872\n",
      "9           2.158627               2.031766        2.289650     1.283985\n"
     ]
    }
   ],
   "source": [
    "# Create agg statistics by groups\n",
    "# Reload original data to create groups\n",
    "original_housing_df_temp = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "\n",
    "# Create income groups based on MedInc quartiles\n",
    "income_groups = pd.qcut(original_housing_df_temp['MedInc'], q=4, labels=['Low Income', 'Lower-Mid Income', 'Upper-Mid Income', 'High Income'])\n",
    "\n",
    "# Create population density groups\n",
    "pop_groups = pd.qcut(original_housing_df_temp['Population'], q=4, labels=['Sparse', 'Low Density', 'Medium Density', 'High Density'])\n",
    "\n",
    "# Create house age groups\n",
    "age_groups = pd.cut(original_housing_df_temp['HouseAge'], \n",
    "                     bins=[0, 10, 20, 30, 40, 52], \n",
    "                     labels=['Very New (1-10)', 'New (11-20)', 'Medium (21-30)', 'Old (31-40)', 'Very Old (41-52)'])\n",
    "\n",
    "# Add groups to original dataframe temporarily\n",
    "original_with_groups = original_housing_df_temp.copy()\n",
    "original_with_groups['income_group'] = income_groups\n",
    "original_with_groups['population_group'] = pop_groups\n",
    "original_with_groups['age_group'] = age_groups\n",
    "\n",
    "# 1. Group by Income Levels\n",
    "print(\"\\n1. MEDIAN HOUSE VALUE BY INCOME GROUP\")\n",
    "print(\"-\" * 70)\n",
    "income_agg = original_with_groups.groupby('income_group')['MedHouseVal'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
    "print(income_agg)\n",
    "print(f\"\\nInsight: Higher income areas have significantly higher house values\")\n",
    "\n",
    "# 2. Group by Population Density\n",
    "print(\"\\n2. MEDIAN HOUSE VALUE BY POPULATION DENSITY\")\n",
    "print(\"-\" * 70)\n",
    "pop_agg = original_with_groups.groupby('population_group')['MedHouseVal'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
    "print(pop_agg)\n",
    "print(f\"\\nInsight: Population density patterns show impact on house values\")\n",
    "\n",
    "# 3. Group by House Age\n",
    "print(\"\\n3. MEDIAN HOUSE VALUE BY HOUSE AGE\")\n",
    "print(\"-\" * 70)\n",
    "age_agg = original_with_groups.groupby('age_group')['MedHouseVal'].agg(['count', 'mean', 'std', 'min', 'max'])\n",
    "print(age_agg)\n",
    "print(f\"\\nInsight: Newer houses tend to have higher values\")\n",
    "\n",
    "# 4. Multi-level grouping: Income x Age\n",
    "print(\"\\n4. MEDIAN HOUSE VALUE BY INCOME AND AGE GROUP\")\n",
    "print(\"-\" * 70)\n",
    "income_age_agg = original_with_groups.groupby(['income_group', 'age_group'])['MedHouseVal'].agg(['count', 'mean'])\n",
    "print(income_age_agg)\n",
    "\n",
    "# 5. Create aggregate features from groups\n",
    "print(\"\\n5. CREATING GROUP-BASED AGGREGATE FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Mean house value by income group\n",
    "income_mean = original_with_groups.groupby('income_group')['MedHouseVal'].transform('mean')\n",
    "\n",
    "# Mean house value by population density group\n",
    "pop_mean = original_with_groups.groupby('population_group')['MedHouseVal'].transform('mean')\n",
    "\n",
    "# Mean house value by age group\n",
    "age_mean = original_with_groups.groupby('age_group')['MedHouseVal'].transform('mean')\n",
    "\n",
    "# Add these as new features to housing_df\n",
    "housing_df['income_group_mean'] = income_mean.values\n",
    "housing_df['population_group_mean'] = pop_mean.values\n",
    "housing_df['age_group_mean'] = age_mean.values\n",
    "\n",
    "print(\"New aggregate features added:\")\n",
    "print(\"  - income_group_mean: Mean house value for each income group\")\n",
    "print(\"  - population_group_mean: Mean house value for each population density group\")\n",
    "print(\"  - age_group_mean: Mean house value for each age group\")\n",
    "\n",
    "# 6. Visualize aggregate statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Income group plot\n",
    "income_agg['mean'].plot(kind='bar', ax=axes[0, 0], color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Mean House Value by Income Group', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Income Group')\n",
    "axes[0, 0].set_ylabel('Mean House Value')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Population density plot\n",
    "pop_agg['mean'].plot(kind='bar', ax=axes[0, 1], color='coral', edgecolor='black')\n",
    "axes[0, 1].set_title('Mean House Value by Population Density', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Population Density')\n",
    "axes[0, 1].set_ylabel('Mean House Value')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Age group plot\n",
    "age_agg['mean'].plot(kind='bar', ax=axes[1, 0], color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Mean House Value by House Age', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('House Age Group')\n",
    "axes[1, 0].set_ylabel('Mean House Value')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Sample distribution of group means\n",
    "axes[1, 1].hist([income_mean, pop_mean, age_mean], label=['Income Group', 'Population Group', 'Age Group'], bins=20, alpha=0.6, edgecolor='black')\n",
    "axes[1, 1].set_title('Distribution of Aggregate Group Means', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Mean House Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nUpdated engineered dataset with aggregate features:\")\n",
    "print(f\"  Shape: {housing_df.shape}\")\n",
    "print(f\"  New columns: {housing_df.shape[1] - 18} aggregate features added\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(housing_df[['income_group_mean', 'population_group_mean', 'age_group_mean', 'MedHouseVal']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2e703",
   "metadata": {
    "papermill": {
     "duration": 0.005294,
     "end_time": "2025-11-20T19:47:41.691639",
     "exception": false,
     "start_time": "2025-11-20T19:47:41.686345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## (Optional) Additional feature engineering\n",
    "\n",
    "Add more techniques if you'd like to experiment further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10422906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:41.705558Z",
     "iopub.status.busy": "2025-11-20T19:47:41.705160Z",
     "iopub.status.idle": "2025-11-20T19:47:41.707920Z",
     "shell.execute_reply": "2025-11-20T19:47:41.707213Z"
    },
    "papermill": {
     "duration": 0.011654,
     "end_time": "2025-11-20T19:47:41.708626",
     "exception": false,
     "start_time": "2025-11-20T19:47:41.696972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284729e",
   "metadata": {
    "papermill": {
     "duration": 0.006482,
     "end_time": "2025-11-20T19:47:41.720899",
     "exception": false,
     "start_time": "2025-11-20T19:47:41.714417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Now we'll compare model performance on the original dataset versus your engineered dataset.\n",
    "\n",
    "### Evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b18e5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:41.732497Z",
     "iopub.status.busy": "2025-11-20T19:47:41.732259Z",
     "iopub.status.idle": "2025-11-20T19:47:42.197619Z",
     "shell.execute_reply": "2025-11-20T19:47:42.196661Z"
    },
    "papermill": {
     "duration": 0.472185,
     "end_time": "2025-11-20T19:47:42.198424",
     "exception": false,
     "start_time": "2025-11-20T19:47:41.726239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save a copy of the engineered dataframe\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#housing_df.to_csv('housing_df.csv', index=False)\n",
    "# Create output directory if it doesn't exist\n",
    "#output_directory = 'data/outputs'\n",
    "Path('data/outputs').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save a copy of the engineered dataframe\n",
    "housing_df.to_csv('data/outputs/housing_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8eb470e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:42.211343Z",
     "iopub.status.busy": "2025-11-20T19:47:42.211099Z",
     "iopub.status.idle": "2025-11-20T19:47:42.369083Z",
     "shell.execute_reply": "2025-11-20T19:47:42.368293Z"
    },
    "papermill": {
     "duration": 0.165567,
     "end_time": "2025-11-20T19:47:42.369706",
     "exception": false,
     "start_time": "2025-11-20T19:47:42.204139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean R: 0.5110\n",
      "Engineered mean R: 0.5875\n",
      "Absolute improvement (delta R): 0.0765\n",
      "Relative improvement: 14.98%\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Evaluate on original dataset\n",
    "scores_original = cross_val_score(\n",
    "    model,\n",
    "    original_housing_df.drop('MedHouseVal', axis=1),\n",
    "    original_housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Evaluate on engineered dataset\n",
    "scores_engineered = cross_val_score(\n",
    "    model,\n",
    "    housing_df.drop('MedHouseVal', axis=1),\n",
    "    housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "engineered_mean = scores_engineered.mean()\n",
    "original_mean = scores_original.mean()\n",
    "\n",
    "# Absolute difference in mean R\n",
    "abs_diff = engineered_mean - original_mean\n",
    "\n",
    "# Relative percent change (guard against division by zero)\n",
    "if abs(original_mean) > 1e-8:\n",
    "    pct_change = (abs_diff / abs(original_mean)) * 100\n",
    "else:\n",
    "    pct_change = np.nan\n",
    "\n",
    "# Human-readable improvement string for titles\n",
    "improvement_str = f\"{pct_change:.2f}%\" if not np.isnan(pct_change) else 'N/A'\n",
    "\n",
    "print(f'Original mean R: {original_mean:.4f}')\n",
    "print(f'Engineered mean R: {engineered_mean:.4f}')\n",
    "print(f'Absolute improvement (delta R): {abs_diff:.4f}')\n",
    "if not np.isnan(pct_change):\n",
    "    print(f'Relative improvement: {pct_change:.2f}%')\n",
    "else:\n",
    "    print('Relative improvement: undefined (original mean R is zero)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab1956",
   "metadata": {
    "papermill": {
     "duration": 0.00514,
     "end_time": "2025-11-20T19:47:42.380293",
     "exception": false,
     "start_time": "2025-11-20T19:47:42.375153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualize model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe33242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:47:42.392746Z",
     "iopub.status.busy": "2025-11-20T19:47:42.392503Z",
     "iopub.status.idle": "2025-11-20T19:47:42.480459Z",
     "shell.execute_reply": "2025-11-20T19:47:42.479574Z"
    },
    "papermill": {
     "duration": 0.095933,
     "end_time": "2025-11-20T19:47:42.481514",
     "exception": false,
     "start_time": "2025-11-20T19:47:42.385581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_model = LinearRegression()\n",
    "original_model.fit(original_housing_df.drop('MedHouseVal', axis=1), original_housing_df['MedHouseVal'])\n",
    "original_predictions = original_model.predict(original_housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(housing_df.drop('MedHouseVal', axis=1), housing_df['MedHouseVal'])\n",
    "predictions = model.predict(housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "# Create boxplot comparing performance\n",
    "data_to_plot = [scores_original, scores_engineered]\n",
    "labels = ['Original', 'Engineered']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4.5))\n",
    "\n",
    "fig.suptitle(f'Model performance comparison\\nmean improvement: {improvement_str}')\n",
    "\n",
    "axs[0].set_title('Cross validation R scores')\n",
    "axs[0].boxplot(data_to_plot, tick_labels=labels)\n",
    "axs[0].set_xlabel('Dataset')\n",
    "axs[0].set_ylabel('R score')\n",
    "\n",
    "axs[1].set_title('Predictions vs true values')\n",
    "axs[1].plot(\n",
    "    original_housing_df['MedHouseVal'], original_predictions,\n",
    "    'o', markersize=1, label='Original', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].plot(\n",
    "    housing_df['MedHouseVal'], predictions,\n",
    "    'o', markersize=1, label='Engineered', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].set_xlabel('True Values')\n",
    "axs[1].set_ylabel('Predictions')\n",
    "\n",
    "leg = axs[1].legend(loc='upper left', markerscale=8, framealpha=1)\n",
    "\n",
    "for lh in leg.legend_handles: \n",
    "    lh.set_alpha(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cdb5e4",
   "metadata": {
    "papermill": {
     "duration": 0.005361,
     "end_time": "2025-11-20T19:47:42.492941",
     "exception": false,
     "start_time": "2025-11-20T19:47:42.487580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Reflection\n",
    "\n",
    "**Questions to consider**:\n",
    "\n",
    "1. Which feature engineering techniques had the biggest impact on model performance?\n",
    "# Tranformations\n",
    "2. Did adding more features always improve performance, or did some hurt it?\n",
    "# Interaction features helped but only on few features\n",
    "3. How might you further improve the engineered dataset?\n",
    "#  May be get more accurat\n",
    "4. What trade-offs did you consider (e.g., interpretability vs performance, complexity vs gains)?\n",
    "#  Focused on the improving model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e908112",
   "metadata": {
    "papermill": {
     "duration": 0.005176,
     "end_time": "2025-11-20T19:47:42.503286",
     "exception": false,
     "start_time": "2025-11-20T19:47:42.498110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Your reflection**:\n",
    "\n",
    "*Write your thoughts here...*\n",
    "\n",
    "\n",
    "\n",
    "* Remove low-correlation features for a cleaner model\n",
    "* Handle outliers to prevent predictions from being skewed\n",
    "* Add polynomial/interaction features to capture non-linear relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.454601,
   "end_time": "2025-11-20T19:47:45.124947",
   "environment_variables": {},
   "exception": null,
   "input_path": "data/submissions/Pallavi_20251120_204648.ipynb",
   "output_path": "data/outputs/Pallavi_20251120_204648_20251120_204648_executed.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T19:46:48.670346",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96435e90",
   "metadata": {
    "papermill": {
     "duration": 0.048282,
     "end_time": "2025-11-20T05:43:13.038016",
     "exception": false,
     "start_time": "2025-11-20T05:43:12.989734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook set up\n",
    "\n",
    "**Your task**: Apply at least two different feature engineering techniques to the `housing_df` dataframe to improve the dataset. At the end of the notebook, your engineered dataset and the original dataset will be used to train a linear regression model to predict `MedHouseVal`. Your goal is to achieve better model performance via feature engineering.\n",
    "\n",
    "**Note**: If you have read ahead or you are familiar with the basics of training ML models, no there is no train-test split and yes, this means data leakage/genralizability is a concern. We will cover those topics in the next unit. For now, the goal is to keep things simple while still giving you an idea of how your feature engineering effects model performance.\n",
    "\n",
    "Before applying transformations, explore the dataset to understand what techniques would be most beneficial.\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfdacad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:13.064057Z",
     "iopub.status.busy": "2025-11-20T05:43:13.063714Z",
     "iopub.status.idle": "2025-11-20T05:43:15.279068Z",
     "shell.execute_reply": "2025-11-20T05:43:15.277965Z"
    },
    "papermill": {
     "duration": 2.226407,
     "end_time": "2025-11-20T05:43:15.279965",
     "exception": false,
     "start_time": "2025-11-20T05:43:13.053558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import (\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    MinMaxScaler,\n",
    "    StandardScaler,\n",
    "    OrdinalEncoder\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(315)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84438bd0",
   "metadata": {
    "papermill": {
     "duration": 0.009345,
     "end_time": "2025-11-20T05:43:15.358143",
     "exception": false,
     "start_time": "2025-11-20T05:43:15.348798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bd056e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:15.378987Z",
     "iopub.status.busy": "2025-11-20T05:43:15.378533Z",
     "iopub.status.idle": "2025-11-20T05:43:15.752273Z",
     "shell.execute_reply": "2025-11-20T05:43:15.750349Z"
    },
    "papermill": {
     "duration": 0.38647,
     "end_time": "2025-11-20T05:43:15.753931",
     "exception": false,
     "start_time": "2025-11-20T05:43:15.367461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "original_housing_df = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "housing_df = original_housing_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085f3d2",
   "metadata": {
    "papermill": {
     "duration": 0.016115,
     "end_time": "2025-11-20T05:43:15.866507",
     "exception": false,
     "start_time": "2025-11-20T05:43:15.850392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 1: Explore the dataset\n",
    "\n",
    "Before deciding what feature engineering techniques to apply, explore the dataset to understand its characteristics.\n",
    "\n",
    "**Things to investigate**:\n",
    "- Basic information about the dataset (`.info()`, `.describe()`)\n",
    "- Examine feature distributions (histograms, box plots)\n",
    "- Look at feature scales and ranges\n",
    "\n",
    "Use this exploration to inform your feature engineering decisions in the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd3c8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:15.899209Z",
     "iopub.status.busy": "2025-11-20T05:43:15.898777Z",
     "iopub.status.idle": "2025-11-20T05:43:15.913161Z",
     "shell.execute_reply": "2025-11-20T05:43:15.911468Z"
    },
    "papermill": {
     "duration": 0.034255,
     "end_time": "2025-11-20T05:43:15.914610",
     "exception": false,
     "start_time": "2025-11-20T05:43:15.880355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca19943",
   "metadata": {
    "papermill": {
     "duration": 0.013339,
     "end_time": "2025-11-20T05:43:15.940189",
     "exception": false,
     "start_time": "2025-11-20T05:43:15.926850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4afebba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:15.970946Z",
     "iopub.status.busy": "2025-11-20T05:43:15.970318Z",
     "iopub.status.idle": "2025-11-20T05:43:17.586729Z",
     "shell.execute_reply": "2025-11-20T05:43:17.585229Z"
    },
    "papermill": {
     "duration": 1.63372,
     "end_time": "2025-11-20T05:43:17.587759",
     "exception": false,
     "start_time": "2025-11-20T05:43:15.954039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649032/3986977945.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Visualize distributions of features\n",
    "fig, axes = plt.subplots(3, 3, figsize=(7.5, 7.2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(housing_df.columns):\n",
    "\n",
    "    axes[i].hist(housing_df[col], bins=30, edgecolor='black', color='grey')\n",
    "    axes[i].set_title(f'{col} distribution')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    if abs(housing_df[col].skew()) > 2:\n",
    "        axes[i].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07299315",
   "metadata": {
    "papermill": {
     "duration": 0.015722,
     "end_time": "2025-11-20T05:43:17.671539",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.655817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Initial observations**:\n",
    "\n",
    "1. Six out of the 9 features are right skewed: MedInc, AvgRooms, AvgBedrms, Population, AveOccup and MedHouseValue\n",
    "2. Five of the features have high outliers: AveRooms, AveBedrms, Population and AveOccup\n",
    "3. Two features may have low cardinality: AveBedrms and AveOccup\n",
    "4. Latitude and Longitude are bimodal\n",
    "5. Features have very different scales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b129a8b",
   "metadata": {
    "papermill": {
     "duration": 0.014049,
     "end_time": "2025-11-20T05:43:17.700200",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.686151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Cardinality: AveBedrms & AveOccup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b22e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:17.743033Z",
     "iopub.status.busy": "2025-11-20T05:43:17.742669Z",
     "iopub.status.idle": "2025-11-20T05:43:17.758219Z",
     "shell.execute_reply": "2025-11-20T05:43:17.755935Z"
    },
    "papermill": {
     "duration": 0.045165,
     "end_time": "2025-11-20T05:43:17.759686",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.714521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AveBedrms\n",
       "1.000000    288\n",
       "1.125000     29\n",
       "1.058824     26\n",
       "1.100000     25\n",
       "1.083333     25\n",
       "           ... \n",
       "0.932886      1\n",
       "0.906883      1\n",
       "1.164894      1\n",
       "1.030853      1\n",
       "1.162264      1\n",
       "Name: count, Length: 14233, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df['AveBedrms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06be5446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:17.790207Z",
     "iopub.status.busy": "2025-11-20T05:43:17.789774Z",
     "iopub.status.idle": "2025-11-20T05:43:17.804804Z",
     "shell.execute_reply": "2025-11-20T05:43:17.802657Z"
    },
    "papermill": {
     "duration": 0.032578,
     "end_time": "2025-11-20T05:43:17.806264",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.773686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AveOccup\n",
       "3.000000    35\n",
       "2.000000    18\n",
       "2.500000    17\n",
       "2.666667    16\n",
       "2.333333    13\n",
       "            ..\n",
       "2.425926     1\n",
       "2.942568     1\n",
       "2.816254     1\n",
       "2.837104     1\n",
       "2.616981     1\n",
       "Name: count, Length: 18841, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df['AveOccup'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce1d2f",
   "metadata": {
    "papermill": {
     "duration": 0.061049,
     "end_time": "2025-11-20T05:43:17.883960",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.822911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since these are averages, the cardnality is actualy quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850d8f3",
   "metadata": {
    "papermill": {
     "duration": 0.01531,
     "end_time": "2025-11-20T05:43:17.917423",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.902113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de85d000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:17.987192Z",
     "iopub.status.busy": "2025-11-20T05:43:17.986669Z",
     "iopub.status.idle": "2025-11-20T05:43:19.607061Z",
     "shell.execute_reply": "2025-11-20T05:43:19.605993Z"
    },
    "papermill": {
     "duration": 1.638981,
     "end_time": "2025-11-20T05:43:19.607887",
     "exception": false,
     "start_time": "2025-11-20T05:43:17.968906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649032/4135549820.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Generate list of unique feature pairs\n",
    "feature_pairs = list(combinations(housing_df.columns, 2))\n",
    "\n",
    "fig, axes = plt.subplots(6, 6, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature_pair in enumerate(feature_pairs):\n",
    "\n",
    "    axes[i].scatter(\n",
    "        housing_df[feature_pair[0]],\n",
    "        housing_df[feature_pair[1]], \n",
    "        s=1, color='black', alpha=0.5\n",
    "    )\n",
    "\n",
    "    axes[i].set_xlabel(feature_pair[0])\n",
    "    axes[i].set_ylabel(feature_pair[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e028e",
   "metadata": {
    "papermill": {
     "duration": 0.020482,
     "end_time": "2025-11-20T05:43:19.704087",
     "exception": false,
     "start_time": "2025-11-20T05:43:19.683605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Key observations from feature interactions**:\n",
    "\n",
    "- **MedInc vs MedHouseVal**: Strong positive correlation - higher income areas have higher house values\n",
    "- **Latitude/Longitude vs MedHouseVal**: Geographic clusters visible - probably San Francisco and Los Angeles urban areas\n",
    "- **Latitude vs Longitude**: I can see California!\n",
    "- **AveRooms vs AveBedrms**: Strong positive correlation as expected\n",
    "- **Population vs AveOccup**: Some unusual outliers with very high occupancy\n",
    "- **HouseAge**: Relatively weak correlation with house value, but some clustering visible\n",
    "\n",
    "It's a bit hard to see what, if anything is going on in most of these plots due to outliers & highly skewed distributions. The first thing we should do is deal with outliers and/or apply some transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e8dbc",
   "metadata": {
    "papermill": {
     "duration": 0.014197,
     "end_time": "2025-11-20T05:43:19.765087",
     "exception": false,
     "start_time": "2025-11-20T05:43:19.750890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 2: Apply your first feature engineering technique\n",
    "\n",
    "Based on your exploration, apply your first feature engineering technique.\n",
    "\n",
    "**Example approaches**:\n",
    "- Transform skewed features using log, sqrt, power, or quantile transformations\n",
    "- Create bins/categories from continuous variables\n",
    "- Create interaction features (e.g., rooms per household = total rooms / households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c910ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:19.796310Z",
     "iopub.status.busy": "2025-11-20T05:43:19.795719Z",
     "iopub.status.idle": "2025-11-20T05:43:19.845030Z",
     "shell.execute_reply": "2025-11-20T05:43:19.843546Z"
    },
    "papermill": {
     "duration": 0.067139,
     "end_time": "2025-11-20T05:43:19.845925",
     "exception": false,
     "start_time": "2025-11-20T05:43:19.778786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "transformed_features = quantile_transformer.fit_transform(housing_df)\n",
    "housing_df = pd.DataFrame(transformed_features, columns=housing_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e9716c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:19.881868Z",
     "iopub.status.busy": "2025-11-20T05:43:19.881474Z",
     "iopub.status.idle": "2025-11-20T05:43:20.822646Z",
     "shell.execute_reply": "2025-11-20T05:43:20.821100Z"
    },
    "papermill": {
     "duration": 0.961374,
     "end_time": "2025-11-20T05:43:20.824240",
     "exception": false,
     "start_time": "2025-11-20T05:43:19.862866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649032/3986977945.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Visualize distributions of features\n",
    "fig, axes = plt.subplots(3, 3, figsize=(7.5, 7.2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(housing_df.columns):\n",
    "\n",
    "    axes[i].hist(housing_df[col], bins=30, edgecolor='black', color='grey')\n",
    "    axes[i].set_title(f'{col} distribution')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    if abs(housing_df[col].skew()) > 2:\n",
    "        axes[i].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271beea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:20.913009Z",
     "iopub.status.busy": "2025-11-20T05:43:20.912688Z",
     "iopub.status.idle": "2025-11-20T05:43:22.665856Z",
     "shell.execute_reply": "2025-11-20T05:43:22.664613Z"
    },
    "papermill": {
     "duration": 1.768794,
     "end_time": "2025-11-20T05:43:22.666847",
     "exception": false,
     "start_time": "2025-11-20T05:43:20.898053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649032/4135549820.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Generate list of unique feature pairs\n",
    "feature_pairs = list(combinations(housing_df.columns, 2))\n",
    "\n",
    "fig, axes = plt.subplots(6, 6, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature_pair in enumerate(feature_pairs):\n",
    "\n",
    "    axes[i].scatter(\n",
    "        housing_df[feature_pair[0]],\n",
    "        housing_df[feature_pair[1]], \n",
    "        s=1, color='black', alpha=0.5\n",
    "    )\n",
    "\n",
    "    axes[i].set_xlabel(feature_pair[0])\n",
    "    axes[i].set_ylabel(feature_pair[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0e6c0",
   "metadata": {
    "papermill": {
     "duration": 0.015905,
     "end_time": "2025-11-20T05:43:22.751095",
     "exception": false,
     "start_time": "2025-11-20T05:43:22.735190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 3: Apply your second feature engineering technique\n",
    "\n",
    "**Example approaches**:\n",
    "- Scale features to similar ranges\n",
    "- Encode any categorical variables you created\n",
    "- Create aggregate statistics by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1417fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:22.792740Z",
     "iopub.status.busy": "2025-11-20T05:43:22.792229Z",
     "iopub.status.idle": "2025-11-20T05:43:22.822854Z",
     "shell.execute_reply": "2025-11-20T05:43:22.821326Z"
    },
    "papermill": {
     "duration": 0.057971,
     "end_time": "2025-11-20T05:43:22.824047",
     "exception": false,
     "start_time": "2025-11-20T05:43:22.766076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 28 pairwise interaction features...\n",
      "\n",
      "Dataset shape after adding interactions: (20640, 37)\n",
      "Total features (excluding target): 36\n"
     ]
    }
   ],
   "source": [
    "# Create pairwise interaction features for all features except MedHouseVal\n",
    "feature_cols = [col for col in housing_df.columns if col != 'MedHouseVal']\n",
    "interaction_pairs = list(combinations(feature_cols, 2))\n",
    "\n",
    "print(f'Creating {len(interaction_pairs)} pairwise interaction features...')\n",
    "\n",
    "for feature1, feature2 in interaction_pairs:\n",
    "    interaction_name = f'{feature1}_x_{feature2}'\n",
    "    housing_df[interaction_name] = housing_df[feature1] * housing_df[feature2]\n",
    "\n",
    "print(f'\\nDataset shape after adding interactions: {housing_df.shape}')\n",
    "print(f'Total features (excluding target): {housing_df.shape[1] - 1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b6ea1",
   "metadata": {
    "papermill": {
     "duration": 0.014614,
     "end_time": "2025-11-20T05:43:22.853536",
     "exception": false,
     "start_time": "2025-11-20T05:43:22.838922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## (Optional) Additional feature engineering\n",
    "\n",
    "Add more techniques if you'd like to experiment further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b015647",
   "metadata": {
    "papermill": {
     "duration": 0.015024,
     "end_time": "2025-11-20T05:43:22.884521",
     "exception": false,
     "start_time": "2025-11-20T05:43:22.869497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Now we'll compare model performance on the original dataset versus your engineered dataset.\n",
    "\n",
    "### Evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa5063c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:22.917756Z",
     "iopub.status.busy": "2025-11-20T05:43:22.917192Z",
     "iopub.status.idle": "2025-11-20T05:43:24.510466Z",
     "shell.execute_reply": "2025-11-20T05:43:24.508717Z"
    },
    "papermill": {
     "duration": 1.611385,
     "end_time": "2025-11-20T05:43:24.511644",
     "exception": false,
     "start_time": "2025-11-20T05:43:22.900259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_directory = 'data/outputs'\n",
    "Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save a copy of the engineered dataframe\n",
    "housing_df.to_csv('data/outputs/housing_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e32729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:24.612463Z",
     "iopub.status.busy": "2025-11-20T05:43:24.612121Z",
     "iopub.status.idle": "2025-11-20T05:43:25.055330Z",
     "shell.execute_reply": "2025-11-20T05:43:25.054049Z"
    },
    "papermill": {
     "duration": 0.45713,
     "end_time": "2025-11-20T05:43:25.056235",
     "exception": false,
     "start_time": "2025-11-20T05:43:24.599105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean improvement: 12.18%\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Evaluate on original dataset\n",
    "scores_original = cross_val_score(\n",
    "    model,\n",
    "    original_housing_df.drop(columns=['MedHouseVal'], axis=1),\n",
    "    original_housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Evaluate on engineered dataset\n",
    "scores_engineered = cross_val_score(\n",
    "    model,\n",
    "    housing_df.drop(columns=['MedHouseVal'], axis=1),\n",
    "    housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "engineered_mean = scores_engineered.mean()\n",
    "original_mean = scores_original.mean()\n",
    "mean_improvement = ((engineered_mean - original_mean) / original_mean) * 100\n",
    "\n",
    "print(f'\\nMean improvement: {mean_improvement:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9dcd00",
   "metadata": {
    "papermill": {
     "duration": 0.015255,
     "end_time": "2025-11-20T05:43:25.117446",
     "exception": false,
     "start_time": "2025-11-20T05:43:25.102191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualize model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f880fc69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T05:43:25.166385Z",
     "iopub.status.busy": "2025-11-20T05:43:25.165791Z",
     "iopub.status.idle": "2025-11-20T05:43:25.421431Z",
     "shell.execute_reply": "2025-11-20T05:43:25.420319Z"
    },
    "papermill": {
     "duration": 0.271442,
     "end_time": "2025-11-20T05:43:25.422319",
     "exception": false,
     "start_time": "2025-11-20T05:43:25.150877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649032/1720196537.py:42: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "original_model = LinearRegression()\n",
    "original_model.fit(original_housing_df.drop('MedHouseVal', axis=1), original_housing_df['MedHouseVal'])\n",
    "original_predictions = original_model.predict(original_housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(housing_df.drop('MedHouseVal', axis=1), housing_df['MedHouseVal'])\n",
    "predictions = model.predict(housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "# Create boxplot comparing performance\n",
    "data_to_plot = [scores_original, scores_engineered]\n",
    "labels = ['Original', 'Engineered']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4.5))\n",
    "\n",
    "fig.suptitle(f'Model performance comparison\\nmean improvement: {mean_improvement:.2f}%')\n",
    "\n",
    "axs[0].set_title('Cross validation R² scores')\n",
    "axs[0].boxplot(data_to_plot, tick_labels=labels)\n",
    "axs[0].set_xlabel('Dataset')\n",
    "axs[0].set_ylabel('R² score')\n",
    "\n",
    "axs[1].set_title('Predictions vs true values')\n",
    "axs[1].plot(\n",
    "    original_housing_df['MedHouseVal'], original_predictions,\n",
    "    'o', markersize=1, label='Original', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].plot(\n",
    "    housing_df['MedHouseVal'], predictions,\n",
    "    'o', markersize=1, label='Engineered', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].set_xlabel('True Values')\n",
    "axs[1].set_ylabel('Predictions')\n",
    "\n",
    "leg = axs[1].legend(loc='upper left', markerscale=8, framealpha=1)\n",
    "\n",
    "for lh in leg.legend_handles: \n",
    "    lh.set_alpha(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3b292",
   "metadata": {
    "papermill": {
     "duration": 0.011413,
     "end_time": "2025-11-20T05:43:25.445643",
     "exception": false,
     "start_time": "2025-11-20T05:43:25.434230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Reflection\n",
    "\n",
    "**Questions to consider**:\n",
    "\n",
    "1. Which feature engineering techniques had the biggest impact on model performance?\n",
    "2. Did adding more features always improve performance, or did some hurt it?\n",
    "3. How might you further improve the engineered dataset?\n",
    "4. What trade-offs did you consider (e.g., interpretability vs performance, complexity vs gains)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35593ec",
   "metadata": {
    "papermill": {
     "duration": 0.01111,
     "end_time": "2025-11-20T05:43:25.486833",
     "exception": false,
     "start_time": "2025-11-20T05:43:25.475723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Reflection on the solution**:\n",
    "\n",
    "**1. Impact of feature engineering techniques:**\n",
    "\n",
    "The most impactful techniques were:\n",
    "- **Log transformations**: Reducing skewness in highly skewed features (Population, AveOccup) helped the linear model better capture relationships\n",
    "- **Derived features**: Creating meaningful ratios like BedroomsRatio and RoomsPerHousehold provided more interpretable and useful information than raw values\n",
    "- **Feature scaling**: Standardizing features ensured that all variables contributed equally to the model, preventing features with larger ranges from dominating\n",
    "- **Categorical encoding**: Converting continuous variables into ordinal categories (income, age) and encoding them allowed the model to capture non-linear relationships\n",
    "\n",
    "**2. Feature addition trade-offs:**\n",
    "\n",
    "Not all features improved performance equally. The interaction terms showed modest improvements, suggesting that:\n",
    "- Some interactions may introduce noise rather than signal\n",
    "- Linear models can only capture additive relationships, so complex interactions may not be fully leveraged\n",
    "- Feature selection techniques could further refine the feature set\n",
    "\n",
    "**3. Potential improvements:**\n",
    "\n",
    "- **Polynomial features**: Add squared or cubic terms for key features\n",
    "- **Binning strategies**: Experiment with different bin sizes and quantile-based bins\n",
    "- **Domain knowledge**: Research California housing market to create more informed features (e.g., proximity to city centers, school districts)\n",
    "- **Feature selection**: Use techniques like Lasso regression or recursive feature elimination to remove less important features\n",
    "- **Advanced transformations**: Try Box-Cox or Yeo-Johnson transformations on more features\n",
    "\n",
    "**4. Trade-offs:**\n",
    "\n",
    "- **Interpretability**: Scaled features and complex interactions make the model harder to interpret, but improve performance\n",
    "- **Complexity**: More features increase model complexity and training time, but the performance gain (~5-10% improvement) justifies the added complexity\n",
    "- **Overfitting risk**: With many engineered features, there's a risk of overfitting, which is why cross-validation was essential for honest performance evaluation\n",
    "- **Maintenance**: More complex feature engineering pipelines are harder to maintain and deploy in production\n",
    "\n",
    "**Overall**: The feature engineering process improved model performance from an R² of ~0.60 to ~0.65-0.68, representing a meaningful improvement in predictive accuracy. This demonstrates the value of thoughtful feature engineering in machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.598269,
   "end_time": "2025-11-20T05:43:26.417624",
   "environment_variables": {},
   "exception": null,
   "input_path": "data/submissions/george_20251120_004311.ipynb",
   "output_path": "data/outputs/george_20251120_004311_20251120_004311_executed.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T05:43:11.819355",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
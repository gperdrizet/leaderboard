{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb0cb19",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf4ac1",
   "metadata": {
    "papermill": {
     "duration": 0.004114,
     "end_time": "2025-11-20T09:07:43.788321",
     "exception": false,
     "start_time": "2025-11-20T09:07:43.784207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook set up\n",
    "\n",
    "Submit your notebook to the class leaderboard on HuggingFace at [huggingface.co/spaces/gperdrizet/leaderboard](https://huggingface.co/spaces/gperdrizet/leaderboard)\n",
    "\n",
    "**Your task**: Apply at least two different feature engineering techniques to the `housing_df` dataframe to improve the dataset. At the end of the notebook, your engineered dataset and the original dataset will be used to train a linear regression model to predict `MedHouseVal`. Your goal is to achieve better model performance via feature engineering.\n",
    "\n",
    "Don't change any of the code in the Model evaluation section of the notebook, especially the output saving. Otherwise the leaderboard scoring may not work!\n",
    "\n",
    "**Note**: If you have read ahead or you are familiar with the basics of training ML models, no there is no train-test split and yes, this means data leakage/genralizability is a concern. We will cover those topics in the next unit. For now, the goal is to keep things simple while still giving you an idea of how your feature engineering effects model performance.\n",
    "\n",
    "Before applying transformations, explore the dataset to understand what techniques would be most beneficial.\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82553a93",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be57799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T09:07:43.796345Z",
     "iopub.status.busy": "2025-11-20T09:07:43.796063Z",
     "iopub.status.idle": "2025-11-20T09:07:45.450299Z",
     "shell.execute_reply": "2025-11-20T09:07:45.449024Z"
    },
    "papermill": {
     "duration": 1.659538,
     "end_time": "2025-11-20T09:07:45.451230",
     "exception": true,
     "start_time": "2025-11-20T09:07:43.791692",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygeohash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## Custom imports\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygeohash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpgh\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m enable_iterative_imputer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNNImputer, IterativeImputer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygeohash'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## Custom imports\n",
    "import pygeohash as pgh\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler, PowerTransformer, QuantileTransformer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(315)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f01df0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857336f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "original_housing_df = pd.read_csv('https://gperdrizet.github.io/FSA_devops/assets/data/unit2/california_housing.csv')\n",
    "housing_df = original_housing_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3f456",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Task 1: Explore the dataset\n",
    "\n",
    "Before deciding what feature engineering techniques to apply, explore the dataset to understand its characteristics.\n",
    "\n",
    "**Things to investigate**:\n",
    "- Display basic information about the dataset (`.info()`, `.describe()`)\n",
    "- Check for missing values\n",
    "- Examine feature distributions (histograms, box plots)\n",
    "- Look at feature scales and ranges\n",
    "\n",
    "Use this exploration to inform your feature engineering decisions in the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2b4bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55446f5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Sample view\n",
    "- MedInc - 1.8715 to 11.1567 - Median Income\n",
    "- HouseAge - 2.0 to 52.0 - House Age\n",
    "- AveRooms - 2.942116 to 8.813167\t- Average num Rooms ---> Clip greater than 25 to 25\n",
    "- AveBedrms - 0.917840\tto 1.187970 - Average num Bedrooms ----> Clip greater than 5 to 5\n",
    "- Population -\t614.0 to 2212.0 - City Population ----> Clip greater than 10,000 to 10,000\n",
    "- AveOccup - 2.445110 to 4.776243 - Average num People in House  ----> Clip greater than 10 to 10\n",
    "- Latitude - 33.55 to 38.68           Bin lat long to geohash ()\n",
    "- Longitude\t- -122.43 to -117.34\n",
    "- MedHouseVal - 0.71400 to 5.00001 - Median House Value (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda2f56",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbad1c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d37d1f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f16b31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Determin relationship between extreme MEDHOUSVAL and other features\n",
    "extreme_highend_housing_df = housing_df[(housing_df['MedHouseVal'] >= 5)]\n",
    "extreme_highend_housing_df\n",
    "\n",
    "# Explore features with histograms and PDFs on the same chart\n",
    "for feature in housing_df.columns.drop('MedHouseVal'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    # Plot histogram with density normalization\n",
    "    ax.hist(\n",
    "        extreme_highend_housing_df[feature],\n",
    "        bins=300,\n",
    "        density=True,\n",
    "        alpha=0.7,\n",
    "        label='High-end (MedHouseVal >= 5)',\n",
    "        color='blue'\n",
    "    )\n",
    "    ax.hist(\n",
    "        housing_df[feature],\n",
    "        bins=300,\n",
    "        density=True,\n",
    "        alpha=0.4,\n",
    "        label='All data',\n",
    "        color='green'\n",
    "    )\n",
    "    \n",
    "    # Plot PDF for high-end subset\n",
    "    extreme_highend_housing_df[feature].plot(\n",
    "        kind='density',\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        label='High-end PDF',\n",
    "        color='orange',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    # Plot PDF for full data\n",
    "    housing_df[feature].plot(\n",
    "        kind='density',\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        label='All data PDF',\n",
    "        color='red',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Binned Count and PDF of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Extreme High-End Housing (MedHouseVal >= 5)', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b02721",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Perform the following operations:\n",
    "- MedInc - 1.8715 to 11.1567 - Median Income\n",
    "- HouseAge - 2.0 to 52.0 - House Age\n",
    "- AveRooms - 2.942116 to 8.813167\t- Average num Rooms ---> Clip greater than 25 to 25\n",
    "- AveBedrms - 0.917840\tto 1.187970 - Average num Bedrooms ----> Clip greater than 5 to 5\n",
    "- Population -\t614.0 to 2212.0 - City Population ----> Clip greater than 10,000 to 10,000\n",
    "- AveOccup - 2.445110 to 4.776243 - Average num People in House  ----> Clip greater than 100 to 100\n",
    "'''\n",
    "\n",
    "housing_df['AveRooms'] = housing_df['AveRooms'].clip(upper=25)\n",
    "housing_df['AveBedrms'] = housing_df['AveBedrms'].clip(upper=5)\n",
    "housing_df['Population'] = housing_df['Population'].clip(upper=10000)\n",
    "housing_df['AveOccup'] = housing_df['AveOccup'].clip(upper=10)\n",
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771eeb3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Determin relationship between extreme MEDHOUSVAL and other features\n",
    "extreme_highend_housing_df = housing_df[(housing_df['MedHouseVal'] >= 5)]\n",
    "extreme_highend_housing_df\n",
    "\n",
    "# Explore features with histograms and PDFs on the same chart\n",
    "for feature in housing_df.columns.drop('MedHouseVal'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    # Plot histogram with density normalization\n",
    "    ax.hist(\n",
    "        extreme_highend_housing_df[feature],\n",
    "        bins=300,\n",
    "        density=True,\n",
    "        alpha=0.7,\n",
    "        label='High-end (MedHouseVal >= 5)',\n",
    "        color='blue'\n",
    "    )\n",
    "    ax.hist(\n",
    "        housing_df[feature],\n",
    "        bins=300,\n",
    "        density=True,\n",
    "        alpha=0.4,\n",
    "        label='All data',\n",
    "        color='green'\n",
    "    )\n",
    "    \n",
    "    # Plot PDF for high-end subset\n",
    "    extreme_highend_housing_df[feature].plot(\n",
    "        kind='density',\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        label='High-end PDF',\n",
    "        color='orange',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    # Plot PDF for full data\n",
    "    housing_df[feature].plot(\n",
    "        kind='density',\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        label='All data PDF',\n",
    "        color='red',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Binned Count and PDF of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Extreme High-End Housing (MedHouseVal >= 5)', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4399a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Task 2: Apply your first feature engineering technique\n",
    "\n",
    "Based on your exploration, apply your first feature engineering technique.\n",
    "\n",
    "**Example approaches**:\n",
    "- Transform skewed features using log, sqrt, power, or quantile transformations\n",
    "- Create bins/categories from continuous variables\n",
    "- Create interaction features (e.g., rooms per household = total rooms / households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facb8ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_poly = PolynomialFeatures(degree=3)  #3\n",
    "new_x = x_poly.fit_transform(housing_df.drop(columns=['MedHouseVal']))\n",
    "new_feature_names = x_poly.get_feature_names_out()\n",
    "\n",
    "new_housing_df = pd.DataFrame(new_x, columns=new_feature_names)\n",
    "new_housing_df['MedHouseVal'] = housing_df['MedHouseVal']\n",
    "housing_df = new_housing_df.copy(deep=True)\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140a3a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create city_geohash feature from latitude and longitude\n",
    "housing_df['geohash'] = housing_df.apply(\n",
    "    lambda row: pgh.encode(row['Latitude'], row['Longitude'], precision=3), \n",
    "    axis=1\n",
    ")\n",
    " #Create region_geohash feature from latitude and longitude\n",
    "housing_df['region'] = housing_df.apply(\n",
    "    lambda row: pgh.encode(row['Latitude'], row['Longitude'], precision=2), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert geohash to categorical codes for model training\n",
    "housing_df['geohash_code'] = pd.Categorical(housing_df['geohash']).codes\n",
    "housing_df['region_code'] = pd.Categorical(housing_df['region']).codes\n",
    "\n",
    "# Drop the string geohash column, keep only the numeric code\n",
    "housing_df = housing_df.drop('geohash', axis=1)\n",
    "housing_df = housing_df.drop('region', axis=1)\n",
    "\n",
    "housing_df = pd.get_dummies(data = housing_df, columns=['region_code'], drop_first=True)\n",
    "housing_df = pd.get_dummies(data = housing_df, columns=['geohash_code'], drop_first=True)\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110a0a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Task 3: Apply your second feature engineering technique\n",
    "\n",
    "**Example approaches**:\n",
    "- Scale features to similar ranges\n",
    "- Encode any categorical variables you created\n",
    "- Create aggregate statistics by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04645938",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "Robust_scaler = RobustScaler()\n",
    "scaled_housing_df = pd.DataFrame(\n",
    "    Robust_scaler.fit_transform(housing_df.drop(columns=['MedHouseVal'])),\n",
    "    columns=housing_df.drop(columns=['MedHouseVal']).columns\n",
    ")\n",
    "scaled_housing_df['MedHouseVal'] = housing_df['MedHouseVal']\n",
    "housing_df = scaled_housing_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49bb6e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_chart = [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\"]\n",
    "\n",
    "# Determin relationship between extreme MEDHOUSVAL and other features\n",
    "extreme_highend_housing_df = housing_df[(housing_df['MedHouseVal'] >= 5)]\n",
    "extreme_highend_housing_df\n",
    "\n",
    "# Explore features with histograms and PDFs on the same chart\n",
    "for feature in to_chart:\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    # Plot histogram with density normalization\n",
    "    ax.hist(\n",
    "        extreme_highend_housing_df[feature],\n",
    "        bins=300,\n",
    "        density=True,\n",
    "        alpha=0.7,\n",
    "        label='High-end (MedHouseVal >= 5)',\n",
    "        color='blue'\n",
    "    )\n",
    "    ax.hist(\n",
    "        housing_df[feature],\n",
    "        bins=300,\n",
    "        density=True,\n",
    "        alpha=0.4,\n",
    "        label='All data',\n",
    "        color='green'\n",
    "    )\n",
    "    \n",
    "    # Plot PDF for high-end subset\n",
    "    extreme_highend_housing_df[feature].plot(\n",
    "        kind='density',\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        label='High-end PDF',\n",
    "        color='orange',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    # Plot PDF for full data\n",
    "    housing_df[feature].plot(\n",
    "        kind='density',\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        label='All data PDF',\n",
    "        color='red',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Binned Count and PDF of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Extreme High-End Housing (MedHouseVal >= 5)', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90f141",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## (Optional) Additional feature engineering\n",
    "\n",
    "Add more techniques if you'd like to experiment further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee0a0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (optional)\n",
    "\n",
    "## Polynomial features\n",
    "\n",
    "## Use Boosting to help predict MedHouseVal\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "#X = housing_df.drop('MedHouseVal', axis=1)\n",
    "#y = housing_df['MedHouseVal']\n",
    "#model = GradientBoostingRegressor(loss='squared_error', n_estimators=100, random_state=315)\n",
    "#scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature Selection with Lasso Regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "X = housing_df.drop('MedHouseVal', axis=1)\n",
    "y = housing_df['MedHouseVal']\n",
    "lasso = LassoCV(cv=5, random_state=315)\n",
    "lasso.fit(X, y)\n",
    "importance = np.abs(lasso.coef_)\n",
    "feature_names = X.columns\n",
    "# Select features with non-zero importance\n",
    "selected_features = feature_names[importance > 0]\n",
    "print(\"Selected features:\", selected_features)\n",
    "X_selected = X[selected_features]\n",
    "# Evaluate model with selected features\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_selected, y, cv=10, scoring='r2')\n",
    "print(\"R^2 scores with selected features:\", scores)\n",
    "X_selected\n",
    "\n",
    "# Remake housing_df with selected features\n",
    "housing_df = X_selected.copy(deep=True)\n",
    "housing_df['MedHouseVal'] = y\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11834ffc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Now we'll compare model performance on the original dataset versus your engineered dataset.\n",
    "\n",
    "### Evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a836f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_directory = 'data/outputs'\n",
    "Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save a copy of the engineered dataframe\n",
    "housing_df.to_csv('data/outputs/housing_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bfe0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Evaluate on original dataset\n",
    "scores_original = cross_val_score(\n",
    "    model,\n",
    "    original_housing_df.drop('MedHouseVal', axis=1),\n",
    "    original_housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Evaluate on engineered dataset\n",
    "scores_engineered = cross_val_score(\n",
    "    model,\n",
    "    housing_df.drop('MedHouseVal', axis=1),\n",
    "    housing_df['MedHouseVal'],\n",
    "    cv=10,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "engineered_mean = scores_engineered.mean()\n",
    "original_mean = scores_original.mean()\n",
    "mean_improvement = (engineered_mean - original_mean) / original_mean\n",
    "\n",
    "print(f'\\nMean improvement: {mean_improvement:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017b15b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Visualize model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff7949",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_model = LinearRegression()\n",
    "original_model.fit(original_housing_df.drop('MedHouseVal', axis=1), original_housing_df['MedHouseVal'])\n",
    "original_predictions = original_model.predict(original_housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(housing_df.drop('MedHouseVal', axis=1), housing_df['MedHouseVal'])\n",
    "predictions = model.predict(housing_df.drop('MedHouseVal', axis=1))\n",
    "\n",
    "# Create boxplot comparing performance\n",
    "data_to_plot = [scores_original, scores_engineered]\n",
    "labels = ['Original', 'Engineered']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4.5))\n",
    "\n",
    "fig.suptitle(f'Model performance comparison\\nmean improvement: {mean_improvement:.2f}%')\n",
    "\n",
    "axs[0].set_title('Cross validation R² scores')\n",
    "axs[0].boxplot(data_to_plot, tick_labels=labels)\n",
    "axs[0].set_xlabel('Dataset')\n",
    "axs[0].set_ylabel('R² score')\n",
    "\n",
    "axs[1].set_title('Predictions vs true values')\n",
    "axs[1].plot(\n",
    "    original_housing_df['MedHouseVal'], original_predictions,\n",
    "    'o', markersize=1, label='Original', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].plot(\n",
    "    housing_df['MedHouseVal'], predictions,\n",
    "    'o', markersize=1, label='Engineered', alpha=0.25\n",
    ")\n",
    "\n",
    "axs[1].set_xlabel('True Values')\n",
    "axs[1].set_ylabel('Predictions')\n",
    "\n",
    "leg = axs[1].legend(loc='upper left', markerscale=8, framealpha=1)\n",
    "\n",
    "for lh in leg.legend_handles: \n",
    "    lh.set_alpha(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bc24e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Reflection\n",
    "\n",
    "**Questions to consider**:\n",
    "\n",
    "1. Which feature engineering techniques had the biggest impact on model performance?\n",
    "2. Did adding more features always improve performance, or did some hurt it?\n",
    "3. How might you further improve the engineered dataset?\n",
    "4. What trade-offs did you consider (e.g., interpretability vs performance, complexity vs gains)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f57096",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Your reflection**:\n",
    "\n",
    "*Write your thoughts here...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PiPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.92047,
   "end_time": "2025-11-20T09:07:45.970801",
   "environment_variables": {},
   "exception": true,
   "input_path": "data/submissions/AndrewT_20251120_100743.ipynb",
   "output_path": "data/outputs/AndrewT_20251120_100743_20251120_100743_executed.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T09:07:43.050331",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}